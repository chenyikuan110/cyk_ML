{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "431677 ,  79\n",
      "{'Z': 0, 'a': 1, 'L': 2, '(': 3, 'h': 4, ' ': 5, 'x': 6, '!': 7, 'R': 8, ':': 9, '*': 10, 'j': 11, 'D': 12, 'W': 13, '?': 14, 'P': 15, 'S': 16, \"'\": 17, 'u': 18, 'i': 19, 'U': 20, 'I': 21, 'X': 22, 'M': 23, '1': 24, 'V': 25, '7': 26, 'N': 27, ';': 28, 'C': 29, ')': 30, 'J': 31, '4': 32, '~': 33, 'A': 34, 'c': 35, 'g': 36, 'G': 37, 'q': 38, '0': 39, '8': 40, '\\t': 41, '.': 42, 'l': 43, 'F': 44, 'r': 45, 'T': 46, 'O': 47, '-': 48, 'b': 49, 'd': 50, 's': 51, '\\n': 52, 'E': 53, 'e': 54, 'K': 55, '3': 56, 'm': 57, '\"': 58, 'Q': 59, 'v': 60, '9': 61, 'y': 62, 'o': 63, '6': 64, 'B': 65, ',': 66, 'z': 67, 'n': 68, 'Y': 69, 'f': 70, 'w': 71, '5': 72, '\\\\': 73, 'p': 74, 't': 75, 'H': 76, 'k': 77, '2': 78}\n",
      "{0: 'Z', 1: 'a', 2: 'L', 3: '(', 4: 'h', 5: ' ', 6: 'x', 7: '!', 8: 'R', 9: ':', 10: '*', 11: 'j', 12: 'D', 13: 'W', 14: '?', 15: 'P', 16: 'S', 17: \"'\", 18: 'u', 19: 'i', 20: 'U', 21: 'I', 22: 'X', 23: 'M', 24: '1', 25: 'V', 26: '7', 27: 'N', 28: ';', 29: 'C', 30: ')', 31: 'J', 32: '4', 33: '~', 34: 'A', 35: 'c', 36: 'g', 37: 'G', 38: 'q', 39: '0', 40: '8', 41: '\\t', 42: '.', 43: 'l', 44: 'F', 45: 'r', 46: 'T', 47: 'O', 48: '-', 49: 'b', 50: 'd', 51: 's', 52: '\\n', 53: 'E', 54: 'e', 55: 'K', 56: '3', 57: 'm', 58: '\"', 59: 'Q', 60: 'v', 61: '9', 62: 'y', 63: 'o', 64: '6', 65: 'B', 66: ',', 67: 'z', 68: 'n', 69: 'Y', 70: 'f', 71: 'w', 72: '5', 73: '\\\\', 74: 'p', 75: 't', 76: 'H', 77: 'k', 78: '2'}\n"
     ]
    }
   ],
   "source": [
    "data = open('HP1.txt','r', encoding=\"utf8\").read();\n",
    "chars = list(set(data))\n",
    "data_size, vocab_size = len(data), len(chars)\n",
    "print(data_size,\", \",vocab_size)\n",
    "\n",
    "char_to_ix = {ch:i for i, ch in enumerate(chars)}\n",
    "ix_to_char = {i:ch for i,ch in enumerate(chars)}\n",
    "print(char_to_ix)\n",
    "print(ix_to_char)\n",
    "\n",
    "def encode(idx,num_entry):\n",
    "    ret = np.zeros(num_entry)\n",
    "    ret[idx] = 1\n",
    "    return ret;\n",
    "\n",
    "def encode_array(array,num_entry):\n",
    "    xs = np.zeros((len(array),num_entry))\n",
    "    for i in range(len(array)):\n",
    "        xs[i][array[i]] = 1; \n",
    "    return xs;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "# Helper functions\n",
    "def softmax(array):\n",
    "    return np.exp(array)/ np.sum(np.exp(array)) # return an array\n",
    "\n",
    "def sigmoid(x):\n",
    "    return (1/(1+np.exp(-x)))\n",
    "\n",
    "def sigmoid_deriv(y):\n",
    "    return (y*(1-y))\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def tanh_deriv(y):\n",
    "    return 1 - pow(np.tanh(y),2)\n",
    "\n",
    "# Partially Recurrent Network - partially-fully dropout recurrent net\n",
    "# \n",
    "# i    h     \n",
    "# i    h     o\n",
    "# i          o\n",
    "# i    h     o\n",
    "# i    h     o\n",
    "# i    h     \n",
    "#\n",
    "class pRNN:\n",
    "    \n",
    "    def __init__ (self, lenIn, lenOut, lenRec, sizeHidden, hiddenRec,\\\n",
    "                  inputs_encoded, targets, \\\n",
    "                  learningRate, dropout_threshold):\n",
    "        \n",
    "        # Hyper parameters\n",
    "        self.lenIn          = lenIn\n",
    "        self.lenOut         = lenOut\n",
    "        self.lenRec         = lenRec\n",
    "        self.sizeHidden     = sizeHidden\n",
    "        self.hiddenRec      = hiddenRec\n",
    "        self.learningRate   = learningRate\n",
    "        self.dropout_threshold = dropout_threshold\n",
    "        \n",
    "        # input & expected output\n",
    "        self.inputs_encoded = inputs_encoded;\n",
    "        self.targets = targets;\n",
    "        \n",
    "        # parameters for inference\n",
    "        self.x  = np.zeros(lenIn)  \n",
    "        self.y  = np.zeros(lenOut)\n",
    "        self.h  = np.zeros(sizeHidden)\n",
    "        self.c  = np.zeros(hiddenRec)\n",
    "        \n",
    "        self.W  = np.zeros((lenOut,sizeHidden)) # for the last fully connected layer\n",
    "        self.GW = np.zeros((lenOut,sizeHidden)) # Gradient, for W-update using RMSprop\n",
    "        self.b  = np.zeros(lenOut)\n",
    "        self.Gb = np.zeros(lenOut)\n",
    "        \n",
    "        # for training phase \n",
    "        self.xs = np.zeros((lenRec,lenIn))\n",
    "        self.ys = np.zeros((lenRec,lenOut))\n",
    "        self.cs = np.zeros((lenRec,hiddenRec))\n",
    "        self.hs = np.zeros((lenRec,sizeHidden))\n",
    "        \n",
    "        # for training phase bookkeeping\n",
    "        self.fg = np.zeros((lenRec,hiddenRec)) # forget gate\n",
    "        self.ig = np.zeros((lenRec,hiddenRec)) # input  gate\n",
    "        self.og = np.zeros((lenRec,hiddenRec)) # output gate\n",
    "        self.mc = np.zeros((lenRec,hiddenRec)) # memory cell state (candidate)\n",
    "        \n",
    "        # LSTM class\n",
    "        self.LSTM_Rec = LSTM(lenIn+hiddenRec,hiddenRec,lenRec,learningRate)\n",
    "        self.FF       = FF(lenIn,sizeHidden-hiddenRec,lenRec,learningRate)\n",
    "        \n",
    "        # Dropout vector\n",
    "        self.dvo = np.zeros((lenRec,sizeHidden));\n",
    "        \n",
    "        ''' end of myRNN.__init__ '''\n",
    "       \n",
    "    ''' This is used when mini-batch is used '''            \n",
    "    def update_inputs_targets(self, inputs_encoded, targets):\n",
    "        self.inputs_encoded  = inputs_encoded\n",
    "        self.targets         = targets\n",
    "    \n",
    "    def fwd_pass(self): \n",
    "                \n",
    "        prev_h = np.zeros_like(self.hs[0])\n",
    "        for t in range(0,self.lenRec):\n",
    "            for i in range(self.dvo.shape[1]):\n",
    "                rand = np.random.random()\n",
    "                if(rand > self.dropout_threshold):\n",
    "                    self.dvo[t][i] = 1;\n",
    "                else:\n",
    "                    self.dvo[t][i] = 0;\n",
    "                    \n",
    "            # update input\n",
    "            self.x    = self.inputs_encoded[t]\n",
    "            self.xs[t]= self.inputs_encoded[t]\n",
    "            \n",
    "            # Recurrent part\n",
    "            self.LSTM_Rec.hx = np.hstack((prev_h[:self.hiddenRec], self.x));\n",
    "            self.LSTM_Rec.dvo = self.dvo[t][:self.hiddenRec];     \n",
    "            cR, hR, fR, iR, mR, oR = self.LSTM_Rec.fwd_pass()            \n",
    "            self.cs[t] = cR\n",
    "            self.hs[t][:self.hiddenRec] = hR\n",
    "            self.fg[t] = fR\n",
    "            self.ig[t] = iR\n",
    "            self.mc[t] = mR\n",
    "            self.og[t] = oR\n",
    "            \n",
    "            # Feed forward part \n",
    "            self.FF.x  = self.x;\n",
    "            self.FF.dvo = self.dvo[t][self.hiddenRec:];     \n",
    "            hN = self.FF.fwd_pass()            \n",
    "            self.hs[t][self.hiddenRec:] = hN\n",
    "      \n",
    "            # output layer - fully connected layer\n",
    "            self.ys[t] = np.dot(self.W,self.hs[t]) + self.b\n",
    "            prev_h = self.hs[t]\n",
    "            \n",
    "        return;              \n",
    "    \n",
    "    def bwd_pass(self):        \n",
    "\n",
    "        avg_loss = 0; # using cross entropy average\n",
    "        c2next_grad  = np.zeros(self.hiddenRec)\n",
    "        h2next_grad  = np.zeros(self.sizeHidden)\n",
    "        \n",
    "        # output bp\n",
    "        W_grad   = np.zeros((self.lenOut,self.sizeHidden))\n",
    "        b_grad  = np.zeros(self.lenOut)\n",
    "        \n",
    "        # LSTM internal bp\n",
    "        hxf_Rec_grad   = np.zeros((self.hiddenRec,self.LSTM_Rec.lenIn));\n",
    "        hxi_Rec_grad   = np.zeros((self.hiddenRec,self.LSTM_Rec.lenIn));\n",
    "        hxm_Rec_grad   = np.zeros((self.hiddenRec,self.LSTM_Rec.lenIn));\n",
    "        hxo_Rec_grad   = np.zeros((self.hiddenRec,self.LSTM_Rec.lenIn));\n",
    "        \n",
    "        hW_grad   = np.zeros((self.sizeHidden-self.hiddenRec,self.FF.lenIn));\n",
    "        hb_grad   = np.zeros(self.sizeHidden-self.hiddenRec)\n",
    "        \n",
    "        fb_grad   = np.zeros(self.hiddenRec)\n",
    "        ib_grad   = np.zeros(self.hiddenRec)\n",
    "        mb_grad   = np.zeros(self.hiddenRec)\n",
    "        ob_grad   = np.zeros(self.hiddenRec)\n",
    "                   \n",
    "        # propagates through time and layers\n",
    "\n",
    "        for t in reversed(range(0,self.lenRec)):\n",
    "            \n",
    "            prob = softmax(self.ys[t]) # prevent zero\n",
    "            prob_fix  = prob + 1e-9\n",
    "#            if(prob[self.targets[t]] == 0):\n",
    "#                for ii in range(10000):\n",
    "#                    print(\"ERR!\",self.ys[t][self.targets[t]],\" \",np.sum(self.ys[t]))\n",
    "                \n",
    "            # cross entropy\n",
    "            err       = np.log(prob_fix[int(self.targets[t])])\n",
    "            avg_loss += err\n",
    "     \n",
    "            dy = copy.deepcopy(prob)\n",
    "            dy[int(self.targets[t])] -= 1\n",
    "            \n",
    "            W_grad += np.dot((np.atleast_2d(dy)).T,np.atleast_2d(self.hs[t]))\n",
    "            b_grad += dy\n",
    "            \n",
    "            dh = np.dot(self.W.T,dy) + h2next_grad\n",
    "\n",
    "            if(t > 0):\n",
    "                prev_h = self.hs[t-1]\n",
    "                prev_c = self.cs[t-1]\n",
    "            else:\n",
    "                prev_h = np.zeros_like(self.hs[0])\n",
    "                prev_c = np.zeros_like(self.cs[0])\n",
    "                \n",
    "            # LSTM RNN part\n",
    "            self.LSTM_Rec.hx = np.hstack((prev_h[:self.hiddenRec],self.xs[t]));\n",
    "            self.LSTM_Rec.c = self.cs[t];\n",
    "            \n",
    "            self.LSTM_Rec.dvo = self.dvo[t][:self.hiddenRec];\n",
    "            \n",
    "            dhxf,dhxi,dhxm,dhxo, dbf,dbi,dbm,dbo, c2next_grad,h2next_grad[:self.hiddenRec],x_grad = \\\n",
    "            self.LSTM_Rec.bwd_pass( dh[:self.hiddenRec], prev_c ,self.fg[t],self.ig[t],\\\n",
    "                                   self.mc[t],self.og[t],\\\n",
    "                                 c2next_grad);\n",
    "            \n",
    "            for ii in range(dhxo.shape[0]):\n",
    "                dhxo[ii] *= self.dvo[t][ii];   \n",
    "                \n",
    "            hxf_Rec_grad +=  dhxf;\n",
    "            hxi_Rec_grad +=  dhxi;  \n",
    "            hxm_Rec_grad +=  dhxm;  \n",
    "            hxo_Rec_grad +=  dhxo;   \n",
    "            \n",
    "            fb_grad[:self.hiddenRec] +=  dbf;\n",
    "            ib_grad[:self.hiddenRec] +=  dbi;\n",
    "            mb_grad[:self.hiddenRec] +=  dbm;\n",
    "            ob_grad[:self.hiddenRec] +=  np.multiply(dbo,self.dvo[t][:self.hiddenRec]);   \n",
    "            \n",
    "            # Feed-Forward part\n",
    "            self.FF.x = self.xs[t];         \n",
    "            dhW_grad, dhb_grad    = self.FF.bwd_pass( dh[self.hiddenRec:] );   \n",
    "            hW_grad += dhW_grad;\n",
    "            hb_grad += dhb_grad;\n",
    "\n",
    "        # update using RMSprop\n",
    "        self.LSTM_Rec.update(hxf_Rec_grad/self.lenRec, hxi_Rec_grad/self.lenRec, \\\n",
    "                           hxm_Rec_grad/self.lenRec, hxo_Rec_grad/self.lenRec, \\\n",
    "                           fb_grad/self.lenRec, ib_grad/self.lenRec, \\\n",
    "                           mb_grad/self.lenRec, ob_grad/self.lenRec);\n",
    "        self.FF.update(hW_grad/self.lenRec, hb_grad/self.lenRec);\n",
    "        \n",
    "        self.update(W_grad/self.lenRec,b_grad/self.lenRec);\n",
    "        \n",
    "        return avg_loss/self.lenRec;\n",
    "            \n",
    "          \n",
    "            \n",
    "    def update(self, W_grad, b_grad):\n",
    "        self.GW = 0.9*self.GW + 0.1*W_grad**2;\n",
    "        self.W -= self.learningRate/np.sqrt(self.GW + 1e-8) * W_grad;\n",
    "        self.Gb = 0.9*self.Gb + 0.1*b_grad**2;\n",
    "        self.b -= self.learningRate/np.sqrt(self.Gb + 1e-8) * b_grad;\n",
    "\n",
    "    def inference(self,x):\n",
    "        # update input\n",
    "        self.x = x\n",
    "        self.LSTM_Rec.hx = np.hstack((self.h[:self.hiddenRec], self.x));\n",
    "        self.LSTM_Rec.dvo = np.ones(self.hiddenRec)   \n",
    "        cR, hR, fR, iR, mR, oR = self.LSTM_Rec.fwd_pass()            \n",
    "        self.c = cR\n",
    "        self.h[:self.hiddenRec] = hR\n",
    "\n",
    "        # Feed forward part \n",
    "        self.FF.x  = self.x;\n",
    "        self.FF.dvo = np.ones(self.sizeHidden-self.hiddenRec)\n",
    "        hN = self.FF.fwd_pass()            \n",
    "        self.h[self.hiddenRec:] = hN\n",
    "\n",
    "        # output layer - may replace with softmax instead\n",
    "        self.y = np.dot(self.W,self.h) + self.b\n",
    "        p   = softmax(self.y)     \n",
    "        return np.random.choice(range(self.lenOut), p=p.ravel())\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LSTM:\n",
    "    \n",
    "    def __init__ (self,lenIn,sizeHidden,lenRec,learningRate):\n",
    "        self.lenIn        = lenIn\n",
    "        self.sizeHidden   = sizeHidden\n",
    "        self.lenRec       = lenRec\n",
    "        self.learningRate = learningRate\n",
    "        \n",
    "        # hx == x is x and h horizontally stacked together\n",
    "        self.hx = np.zeros(lenIn)\n",
    "        self.c = np.zeros(sizeHidden)\n",
    "        self.h = np.zeros(sizeHidden)\n",
    "        \n",
    "        # Weight matrices\n",
    "        self.fW = np.random.random((sizeHidden,lenIn));\n",
    "        self.iW = np.random.random((sizeHidden,lenIn));\n",
    "        self.mW = np.random.random((sizeHidden,lenIn)); # cell state\n",
    "        self.oW = np.random.random((sizeHidden,lenIn));\n",
    "                             \n",
    "        # biases\n",
    "        self.fb = np.zeros(sizeHidden);\n",
    "        self.ib = np.zeros(sizeHidden); \n",
    "        self.mb = np.zeros(sizeHidden); \n",
    "        self.ob = np.zeros(sizeHidden); \n",
    "               \n",
    "        # for RMSprop only\n",
    "        self.GfW = np.random.random((sizeHidden,lenIn));\n",
    "        self.GiW = np.random.random((sizeHidden,lenIn));\n",
    "        self.GmW = np.random.random((sizeHidden,lenIn)); \n",
    "        self.GoW = np.random.random((sizeHidden,lenIn));\n",
    "                             \n",
    "        self.Gfb = np.zeros(sizeHidden);\n",
    "        self.Gib = np.zeros(sizeHidden); \n",
    "        self.Gmb = np.zeros(sizeHidden);\n",
    "        self.Gob = np.zeros(sizeHidden); \n",
    "        \n",
    "        # for dropout\n",
    "        self.dvo = np.zeros(sizeHidden); \n",
    "        ''' end of LSTM.__init__ '''\n",
    "        \n",
    "    def fwd_pass(self):\n",
    "        f       = sigmoid(np.dot(self.fW, self.hx) + self.fb)\n",
    "        i       = sigmoid(np.dot(self.iW, self.hx) + self.ib)\n",
    "        m       = tanh(   np.dot(self.mW, self.hx) + self.mb)        \n",
    "        o       = sigmoid(np.dot(self.oW, self.hx) + self.ob)\n",
    "        o       = np.multiply(o,self.dvo); # dropout\n",
    "        self.c *= f\n",
    "        self.c += i * m\n",
    "        self.h  = o * tanh(self.c)\n",
    "        \n",
    "        return self.c, self.h, f, i, m, o;\n",
    "    \n",
    "    def bwd_pass(self, dh, prev_c, f, i, m, o, c_g):\n",
    "        \n",
    "        dh = np.clip(dh, -6, 6);       \n",
    "        # h = o*tanh(c)\n",
    "        do  = tanh(self.c) * dh\n",
    "        do  = sigmoid_deriv(o)*do\n",
    "        #do  = np.multiply(do,self.dvo)\n",
    "        dhxo = np.dot((np.atleast_2d(do)).T,np.atleast_2d(self.hx)) \n",
    "        \n",
    "        # h = o*tanh(c) - add c_g (c_grad in next timestep, account for the branch here)\n",
    "        dcs = dh * o * tanh_deriv(self.c) + c_g\n",
    "        dcs = np.clip(dcs, -6, 6); \n",
    "        \n",
    "        # c = c_prev * f + m * i\n",
    "        dm = i * dcs\n",
    "        dm = tanh_deriv(m) * dm\n",
    "        dhxm = np.dot((np.atleast_2d(dm)).T,np.atleast_2d(self.hx)) \n",
    "        \n",
    "        # c = c_prev * f + m * i\n",
    "        di  = m * dcs\n",
    "        di  = sigmoid_deriv(i) * di\n",
    "        dhxi = np.dot((np.atleast_2d(di)).T,np.atleast_2d(self.hx)) \n",
    "        \n",
    "        # c = c_prev * f + m * i\n",
    "        df = prev_c * dcs\n",
    "        df = sigmoid_deriv(f) * df\n",
    "        dhxf = np.dot((np.atleast_2d(df)).T,np.atleast_2d(self.hx)) \n",
    "        \n",
    "        # c = c_prev * f + m * i\n",
    "        c_grad  = dcs * f\n",
    "        hx_grad = np.dot(self.fW.T, df) + np.dot(self.iW.T, di) +\\\n",
    "                          np.dot(self.oW.T, do) + np.dot(self.mW.T, dm)\n",
    "        \n",
    "        \n",
    "        return dhxf,dhxi,dhxm,dhxo,df,di,dm,do,c_grad,hx_grad[:self.sizeHidden],hx_grad[self.sizeHidden:];\n",
    "    \n",
    "    def update(self, f_grad, i_grad, m_grad, o_grad, fb_grad, ib_grad, mb_grad, ob_grad):\n",
    "\n",
    "        self.GfW = 0.9*self.GfW + 0.1*f_grad**2\n",
    "        self.GiW = 0.9*self.GiW + 0.1*i_grad**2\n",
    "        self.GmW = 0.9*self.GmW + 0.1*m_grad**2\n",
    "        self.GoW = 0.9*self.GoW + 0.1*o_grad**2\n",
    "        \n",
    "        self.Gfb = 0.9*self.Gfb + 0.1*fb_grad**2\n",
    "        self.Gib = 0.9*self.Gib + 0.1*ib_grad**2\n",
    "        self.Gmb = 0.9*self.Gmb + 0.1*mb_grad**2\n",
    "        self.Gob = 0.9*self.Gob + 0.1*ob_grad**2\n",
    "        \n",
    "        self.fW -= self.learningRate/np.sqrt(self.GfW + 1e-8) * f_grad\n",
    "        self.iW -= self.learningRate/np.sqrt(self.GiW + 1e-8) * i_grad\n",
    "        self.mW -= self.learningRate/np.sqrt(self.GmW + 1e-8) * m_grad\n",
    "        self.oW -= self.learningRate/np.sqrt(self.GoW + 1e-8) * o_grad\n",
    "        \n",
    "        self.fb -= self.learningRate/np.sqrt(self.Gfb + 1e-8) * fb_grad\n",
    "        self.ib -= self.learningRate/np.sqrt(self.Gib + 1e-8) * ib_grad\n",
    "        self.mb -= self.learningRate/np.sqrt(self.Gmb + 1e-8) * mb_grad\n",
    "        self.ob -= self.learningRate/np.sqrt(self.Gob + 1e-8) * ob_grad\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FF:\n",
    "    \n",
    "    def __init__ (self,lenIn,sizeHidden,lenRec,learningRate):\n",
    "        self.lenIn        = lenIn\n",
    "        self.sizeHidden   = sizeHidden\n",
    "        self.lenRec       = lenRec\n",
    "        self.learningRate = learningRate\n",
    "        \n",
    "        # hx == x is x and h horizontally stacked together\n",
    "        self.x = np.zeros(lenIn)\n",
    "        self.h = np.zeros(sizeHidden)\n",
    "        \n",
    "        # Weight matrices\n",
    "        self.hW = np.random.random((sizeHidden,lenIn));\n",
    "                            \n",
    "        # biases\n",
    "        self.hb = np.zeros(sizeHidden);\n",
    "             \n",
    "        # for RMSprop only\n",
    "        self.GhW = np.random.random((sizeHidden,lenIn));\n",
    "        self.Ghb = np.zeros(sizeHidden); \n",
    "        \n",
    "        # for dropout\n",
    "        self.dvo = np.zeros(sizeHidden); \n",
    "        ''' end of LSTM.__init__ '''\n",
    "        \n",
    "    def fwd_pass(self):\n",
    "        self.h       = tanh(np.dot(self.hW, self.x) + self.hb)\n",
    "        #self.h       = np.multiply(self.h,self.dvo); # dropout\n",
    "        return self.h;\n",
    "    \n",
    "    def bwd_pass(self, dh):\n",
    "        \n",
    "        dh = np.clip(dh, -6, 6);       \n",
    "        dh  = tanh_deriv(self.h)*dh\n",
    "        dhb = dh;\n",
    "        dhW = np.dot((np.atleast_2d(dh)).T,np.atleast_2d(self.x)) \n",
    "        \n",
    "        return dhW, dhb;\n",
    "    \n",
    "    def update(self, hW_grad, hb_grad):\n",
    "\n",
    "        self.GhW = 0.9*self.GhW+ 0.1*hW_grad**2\n",
    "        self.Ghb = 0.9*self.Ghb+ 0.1*hb_grad**2\n",
    "        \n",
    "        self.hW -= self.learningRate/np.sqrt(self.GhW + 1e-8) * hW_grad\n",
    "        self.hb -= self.learningRate/np.sqrt(self.Ghb + 1e-8) * hb_grad\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harry Potter and the Sorcerer's Stone\n",
      "CHAPTER ONE\n",
      "THE BOY WHO LIVED\n",
      "Mr. and\n",
      "inputs [76, 1, 45, 45, 62, 5, 15, 63, 75, 75, 54, 45, 5, 1, 68, 50, 5, 75, 4, 54, 5, 16, 63, 45, 35, 54, 45, 54, 45, 17, 51, 5, 16, 75, 63, 68, 54, 52, 29, 76, 34, 15, 46, 53, 8, 5, 47, 27, 53, 52, 46, 76, 53, 5, 65, 47, 69, 5, 13, 76, 47, 5, 2, 21, 25, 53, 12, 52, 23, 45, 42, 5, 1, 68, 50]\n",
      "arry Potter and the Sorcerer's Stone\n",
      "CHAPTER ONE\n",
      "THE BOY WHO LIVED\n",
      "Mr. and \n",
      "targets [1, 45, 45, 62, 5, 15, 63, 75, 75, 54, 45, 5, 1, 68, 50, 5, 75, 4, 54, 5, 16, 63, 45, 35, 54, 45, 54, 45, 17, 51, 5, 16, 75, 63, 68, 54, 52, 29, 76, 34, 15, 46, 53, 8, 5, 47, 27, 53, 52, 46, 76, 53, 5, 65, 47, 69, 5, 13, 76, 47, 5, 2, 21, 25, 53, 12, 52, 23, 45, 42, 5, 1, 68, 50, 5]\n",
      "!!!! 431677\n",
      "0 err: -4.36944777346702  R.learningRate: 0.1 dropout_threshold: 0.09999999999999998\n",
      "Z\n",
      "<Inference>:\n",
      "E ET\n",
      "H EEr\n",
      "onndo\n",
      "nHroO POen er\n",
      "ErrEeEH e\n",
      "\n",
      "<Predict>:\n",
      "<Predict>: onenHtHOoddtrna\n",
      "Onano\n",
      "toH n\n",
      "ttE HrHOOaOd\n",
      "<Targets>: arry Potter and the Sorcerer's Stone\n",
      "CHA\n",
      "500 err: -2.4352125142019485  R.learningRate: 0.09756147122503571 dropout_threshold: 0.1292623452995716\n",
      "7\n",
      "<Inference>:\n",
      "to s ut,noung, a Duwley Harry cumpif ing\n",
      "\n",
      "<Predict>:\n",
      "<Predict>: eiil',tafhi  .nendn shi sursley .Doumht \n",
      "<Targets>: owded withfamilies. The Dursleys bought \n",
      "1000 err: -2.269857639438292  R.learningRate: 0.09524187090179798 dropout_threshold: 0.15709754917842422\n",
      "\n",
      "\n",
      "<Inference>:\n",
      "\"sot gand fre fath tat it kne gon he to \n",
      "\n",
      "<Predict>:\n",
      "<Predict>:  ont? ht rwho noms-e  ryDbaet faardasio-\n",
      "<Targets>:  only one who saw herfor what she was --\n",
      "1500 err: -2.1438590737887644  R.learningRate: 0.09303539882125289 dropout_threshold: 0.18357521414496525\n",
      "2\n",
      "<Inference>:\n",
      " seed Mus your lot masike chor and in th\n",
      "\n",
      "<Predict>:\n",
      "<Predict>: o   wurte eudleK  \n",
      "\"I s met Ioi ng fhot \n",
      "<Targets>:  to curse Dudley.\"\n",
      "\"I'm not sayin' that'\n",
      "2000 err: -2.0084959023712337  R.learningRate: 0.0909365376538991 dropout_threshold: 0.2087615481532109\n",
      "V\n",
      "<Inference>:\n",
      "ooring and the to hbout'os if itsd, \"Wha\n",
      "\n",
      "<Predict>:\n",
      "<Predict>: inmathlies aeoo  re,wtdshhe woouk  hnk s\n",
      "<Targets>: o with his brothers and the broomstick h\n",
      "2500 err: -2.213359685880986  R.learningRate: 0.08894003915357025 dropout_threshold: 0.23271953015715707\n",
      "s\n",
      "<Inference>:\n",
      " and Qurd a stand Rottell s the wast ofw\n",
      "\n",
      "<Predict>:\n",
      "<Predict>: i an iasta an fl trrlhff e rys wn hell  \n",
      "<Targets>: t it was stuffed full ofgarlic as well, \n",
      "3000 err: -2.193441168789762  R.learningRate: 0.0870409110340859 dropout_threshold: 0.25550906759096925\n",
      "k\n",
      "<Inference>:\n",
      " ag with -- wheey hemese as hut oply bli\n",
      "\n",
      "<Predict>:\n",
      "<Predict>: sdhs gh hoffah totshn onp taaredft spfsn\n",
      "<Targets>: nted to do was put asmuch space as possi\n",
      "3500 err: -2.3346357984694177  R.learningRate: 0.08523440448593567 dropout_threshold: 0.2771871461687719\n",
      "1\n",
      "<Inference>:\n",
      "cissbowg Wusing, the seom.\n",
      "(Harryer, to \n",
      "\n",
      "<Predict>:\n",
      "<Predict>:  ren\"\n",
      "\"Biryohes nnt's wameu ,rtuds   Jof\n",
      "<Targets>: ame!\"\n",
      "\"But this isn't soccer, Dean,\" Ron\n",
      "4000 err: -2.3459171394247256  R.learningRate: 0.08351600230178197 dropout_threshold: 0.2978079723786164\n",
      "d\n",
      "<Inference>:\n",
      " of notTewoucd and thatroved a clough. I\n",
      "\n",
      "<Predict>:\n",
      "<Predict>: edf soond bilht  ho bddsgemheoou~rdsuie \n",
      "<Targets>:  of green light,while a high voice cackl\n",
      "4500 err: -2.5266905974014473  R.learningRate: 0.08188140758108867 dropout_threshold: 0.317423109026936\n",
      "H\n",
      "<Inference>:\n",
      "hroBlysp, of wof they acon hter jowas la\n",
      "\n",
      "<Predict>:\n",
      "<Predict>: npaaeythcl ds glt ou!s,?oo es  ohash tos\n",
      "<Targets>: p the tallest astronomy tower, which was\n",
      "5000 err: -2.1319559036135782  R.learningRate: 0.08032653298563168 dropout_threshold: 0.3360816041724199\n",
      "M\n",
      "<Inference>:\n",
      "cGeare.\n",
      "\"9\n",
      "\"Goly poork bou;ing was bouL \n",
      "\n",
      "<Predict>:\n",
      "<Predict>: rsay fittg h sain\n",
      "\"9ou sast br gednya  e\n",
      "<Targets>:  was goingto say.\n",
      "\"You want to be more c\n",
      "5500 err: -2.5033173830549402  R.learningRate: 0.07884749051902434 dropout_threshold: 0.353830113771708\n",
      "b\n",
      "<Inference>:\n",
      "ed --\"\n",
      "\"\"IM! s,\" nend,bing lirHarry here\n",
      "\n",
      "<Predict>:\n",
      "<Predict>: codld  daaneo-nrite \"Chyeddhhiom hour hr\n",
      "<Targets>: halfthe candy shop.\n",
      "\"Tokens from your fr\n",
      "!!!! 431677\n",
      "6000 err: -2.6007989078982785  R.learningRate: 0.07744058180470133 dropout_threshold: 0.37071301834358406\n",
      "t\n",
      "<Inference>:\n",
      " nae he ared \"But- he dithtentwere.\n",
      "Dul.\n",
      "\n",
      "<Predict>:\n",
      "<Predict>: Mereoirthvnnehnd Molrldai dif bydsspeaee\n",
      "<Targets>: handkerchief and dabbedat her eyes benea\n",
      "6500 err: -2.4460247069384327  R.learningRate: 0.07610228883805081 dropout_threshold: 0.38677253394339034\n",
      "X\n",
      "<Inference>:\n",
      "Sley sall, aly his dramesn't the couldn'\n",
      "\n",
      "<Predict>:\n",
      "<Predict>: ndflfhaedkee nnd Hvaelhn yadeytiy \n",
      "Ha e!\n",
      "<Targets>:  off quickly and dressed silently. Hemus\n",
      "7000 err: -3.5838812419611874  R.learningRate: 0.07482926518957048 dropout_threshold: 0.4020488177251543\n",
      "-\n",
      "<Inference>:\n",
      " don'CCOW\n",
      "Thecind AREOOOTEOOTHEOTENEOOON\n",
      "\n",
      "<Predict>:\n",
      "<Predict>: OeOLEEEKENEErOT ELOTqUNoE\n",
      "LOT\n",
      "RNiMOOIT t\n",
      "<Targets>: YEARS ARE NOT ALLOWED THEIROWN BROOMSTIC\n",
      "7500 err: -2.3039467238525937  R.learningRate: 0.07361832763705074 dropout_threshold: 0.41658006835539113\n",
      "p\n",
      "<Inference>:\n",
      "lat cooude shourf andne, A quit ame witw\n",
      "\n",
      "<Predict>:\n",
      "<Predict>: .ooanlhr fner che ta c  bn aoe faad..d r\n",
      "<Targets>:  drifted over the heads of the chatterin\n",
      "8000 err: -2.2972752858321184  R.learningRate: 0.07246644820586108 dropout_threshold: 0.430402621529667\n",
      "I\n",
      "<Inference>:\n",
      " the the pt \"Potthe \"\n",
      "\"No you here licle\n",
      "\n",
      "<Predict>:\n",
      "<Predict>: hythe eng.,ihthyoher.ng \"V'n tlyoi.reng \n",
      "<Targets>: lytherin,not Slytherin.\n",
      "\"Not Slytherin, \n",
      "8500 err: -2.5147865595712067  R.learningRate: 0.07137074659743634 dropout_threshold: 0.44355104083076397\n",
      "O\n",
      "<Inference>:\n",
      "Maered fory \" ing Pwatttis foy, Poting\n",
      "\"\n",
      "\n",
      "<Predict>:\n",
      "<Predict>: ecyt   wondetsh\"\n",
      "\"aitr \"\n",
      "fhid \"Gcr\"y  fa\n",
      "<Targets>: abies, Parvati.\"\n",
      "\"Look!\" said Malfoy, da\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-e9f3aae2a65a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[0mR\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfwd_pass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m     \u001b[0merr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mR\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbwd_pass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m     \u001b[0merr_curve\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-9ba8ed21aabe>\u001b[0m in \u001b[0;36mbwd_pass\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    160\u001b[0m             \u001b[0mdy\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m             \u001b[0mW_grad\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    163\u001b[0m             \u001b[0mb_grad\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mdy\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Try a reduced/increased drop out probability\n",
    "\n",
    "\n",
    "seq_length,position = 75,0\n",
    "inputs = [char_to_ix[ch] for ch in data[position:position+seq_length]]\n",
    "print(data[position:position+seq_length])\n",
    "print(\"inputs\",inputs)\n",
    "\n",
    "targets = [char_to_ix[ch] for ch in data[position+1:position+seq_length+1]] \n",
    "print(data[position+1:position+seq_length+1])\n",
    "print(\"targets\",targets)\n",
    "\n",
    "n,position = 0,0;\n",
    "epoch = 20*1000;\n",
    "lenIn, lenOut, lenRec = vocab_size,vocab_size, seq_length\n",
    "sizeHidden, hiddenRec, numHiddenLayer = 64,48,1;\n",
    "learningRate = 0.1;\n",
    "dropout_threshold = 0.1;\n",
    "\n",
    "R = pRNN(lenIn, lenOut, lenRec, sizeHidden, hiddenRec, encode_array(inputs,vocab_size),targets, learningRate,dropout_threshold)\n",
    "\n",
    "# training\n",
    "\n",
    "err_curve = [];\n",
    "\n",
    "while n<epoch:\n",
    "    R.learningRate = 0.05+0.05*np.exp(-n/(100*100))\n",
    "    R.dropout_threshold = 0.7-0.6*np.exp(-n/(100*100))\n",
    "    \n",
    "    if(position+seq_length+1 >= len(data) or n == 0):\n",
    "        print(\"!!!!\",len(data))\n",
    "        position = 0;\n",
    "        \n",
    "    inputs  = [char_to_ix[ch] for ch in data[position:position+seq_length]]\n",
    "    targets = [char_to_ix[ch] for ch in data[position+1:position+seq_length+1]] \n",
    "\n",
    "    R.update_inputs_targets(encode_array(inputs,vocab_size),targets)\n",
    "    R.fwd_pass();\n",
    "    \n",
    "    err = R.bwd_pass();\n",
    "    err_curve.append(err);\n",
    "    \n",
    "    if(n%500 == 0):\n",
    "        \n",
    "        print(n,\"err:\",err,\" R.learningRate:\", R.learningRate,\"dropout_threshold:\",R.dropout_threshold)\n",
    "        seed = encode(n % vocab_size,vocab_size)\n",
    "        print(ix_to_char[n % vocab_size])\n",
    "        result = [];\n",
    "        R.h  = np.zeros(sizeHidden)\n",
    "        R.c  = np.zeros(sizeHidden)\n",
    "        print(\"<Inference>:\")\n",
    "        for i in range(40):\n",
    "            ret = R.inference(seed)\n",
    "            result.append(ret)\n",
    "            seed = encode(ret,vocab_size)\n",
    "        decode = ''.join([ix_to_char[ch] for ch in result] )\n",
    "        print(decode)\n",
    "        \n",
    "        print(\"\\n<Predict>:\")\n",
    "        inputs  = [char_to_ix[ch] for ch in data[position:position+seq_length]]\n",
    "        targets = [char_to_ix[ch] for ch in data[position+1:position+seq_length+1]] \n",
    "        result = [];\n",
    "        compare = [];\n",
    "        for i in range(40):\n",
    "            ret = R.inference(encode(inputs[i],vocab_size))\n",
    "            result.append(ret)\n",
    "            compare.append(targets[i])\n",
    "        in_decode = ''.join([ix_to_char[ch] for ch in result] )\n",
    "        cm_decode = ''.join([ix_to_char[ch] for ch in compare] )\n",
    "        print(\"<Predict>:\",in_decode)\n",
    "        print(\"<Targets>:\",cm_decode)\n",
    "    position += seq_length;\n",
    "    n += 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
