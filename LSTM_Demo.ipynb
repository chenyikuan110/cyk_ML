{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import gnumpy as gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Helper functions\n",
    "def softmax(array):\n",
    "    return np.exp(array)/ np.sum(np.exp(array)) # return an array\n",
    "\n",
    "def sigmoid(x):\n",
    "    return (1/(1+np.exp(-x)))\n",
    "\n",
    "def sigmoid_deriv(y):\n",
    "    return (y*(1-y))\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def tanh_deriv(y):\n",
    "    return 1 - pow(np.tanh(y),2)\n",
    "\n",
    "# RNN\n",
    "class myRNN:\n",
    "    \n",
    "    def __init__ (self, lenIn, lenOut, lenRec, sizeHidden, numHiddenLayer,inputs, targets, learningRate, biDir=0):\n",
    "        \n",
    "        # parameter save\n",
    "        self.lenIn          = lenIn;\n",
    "        self.lenOut         = lenOut;\n",
    "        self.lenRec         = lenRec;\n",
    "        self.sizeHidden     = sizeHidden;\n",
    "        self.numHiddenLayer = numHiddenLayer;\n",
    "        self.biDir          = biDir;\n",
    "        self.learningRate   = learningRate;\n",
    "        \n",
    "        # for sampling phase\n",
    "        self.x  = np.zeros(lenIn);  \n",
    "        self.y  = np.zeros(lenOut); \n",
    "        self.W  = np.zeros((lenOut,sizeHidden)); # for the last fully connected layer\n",
    "        self.GW = np.zeros((lenOut,sizeHidden)); # Gradient, for W-update using RMSprop\n",
    "        self.Ob = np.zeros(lenOut);\n",
    "        self.ObW= np.zeros(lenOut);\n",
    "        \n",
    "        ### There is NO need to update h and c for bwd prop. ###\n",
    "        # for training phase - plus 1 because need initialize h,c (as zeros)\n",
    "        self.xs = np.zeros((lenRec+1,lenIn));\n",
    "        self.ys = np.zeros((lenRec+1,lenOut));\n",
    "        self.cs = np.zeros((numHiddenLayer,lenRec+1,sizeHidden));\n",
    "        self.hs = np.zeros((numHiddenLayer,lenRec+1,sizeHidden));\n",
    "        \n",
    "        # for training phase gate output storage - plus 1 for convenience of indexing\n",
    "        self.fg = np.zeros((numHiddenLayer,lenRec+1,sizeHidden)) # forget gate\n",
    "        self.ig = np.zeros((numHiddenLayer,lenRec+1,sizeHidden)) # input  gate\n",
    "        self.og = np.zeros((numHiddenLayer,lenRec+1,sizeHidden)) # output gate\n",
    "        self.mc = np.zeros((numHiddenLayer,lenRec+1,sizeHidden)) # memory cell state (candidate)\n",
    "        \n",
    "        # actual input \n",
    "        self.inputs = inputs;\n",
    "        \n",
    "        # for comparison - add one more entry at the begining since there is no output[0]\n",
    "        self.targets = np.vstack((np.zeros(targets.shape[1]),targets))\n",
    "        \n",
    "        # LSTM class\n",
    "        self.LSTM = [LSTM for i in range(numHiddenLayer)];\n",
    "        \n",
    "        if(numHiddenLayer == 1):\n",
    "            self.LSTM[0] = LSTM(lenIn,sizeHidden,lenRec,learningRate);\n",
    "            \n",
    "        elif(numHiddenLayer == 2):\n",
    "            lenIn1 = lenIn;\n",
    "            lenIn2 = sizeHidden;\n",
    "            if(biDir == 1):\n",
    "                lenIn2  = lenIn+sizeHidden;\n",
    "            self.LSTM[0] = LSTM(lenIn1,sizeHidden,lenRec,learningRate);\n",
    "            self.LSTM[1] = LSTM(lenIn2,sizeHidden,lenRec,learningRate);\n",
    "        \n",
    "        else:\n",
    "            lenIn1 = lenIn;\n",
    "            lenIn2 = sizeHidden;\n",
    "            if(biDir == 1):\n",
    "                lenIn2  = lenIn;\n",
    "            self.LSTM[0] = LSTM(lenIn1,sizeHidden,lenRec,learningRate);\n",
    "            self.LSTM[1] = LSTM(lenIn2,sizeHidden,lenRec,learningRate);\n",
    "            for i in range(2,numHiddenLayer):\n",
    "                self.LSTM[i] = LSTM(lenIn2,sizeHidden,lenRec,learningRate);\n",
    "                \n",
    "    def update_inputs_targets(self, inputs, targets):\n",
    "        self.inputs = inputs;\n",
    "        self.targets = np.vstack((np.zeros(targets.shape[1]),targets))\n",
    "    \n",
    "    def fwd_pass(self):\n",
    "        errSum = 0;\n",
    "        if(self.biDir == 0):          \n",
    "            for j in range(1,self.lenRec+1):\n",
    "                # update input\n",
    "                self.x    = self.inputs[j-1]\n",
    "                self.xs[j]= self.inputs[j-1]\n",
    "                \n",
    "                # first layer\n",
    "                self.LSTM[0].x = self.x;\n",
    "                self.LSTM[0].ph= self.hs[0][j-1];\n",
    "                c, h, f, i, m, o = self.LSTM[0].fwd_pass();\n",
    "                self.fg[0][j] = f;\n",
    "                self.ig[0][j] = i;\n",
    "                self.og[0][j] = o;\n",
    "                self.mc[0][j] = m;\n",
    "                self.cs[0][j] = c;\n",
    "                self.hs[0][j] = h;\n",
    "                \n",
    "                # other layers\n",
    "                if(self.numHiddenLayer > 1):\n",
    "                    for k in range(1,numHiddenLayer):\n",
    "                        self.LSTM[k].x = self.hs[k-1][j];\n",
    "                        self.LSTM[k].ph= self.hs[k][j-1];\n",
    "                        c, h, f, i, m, o = self.LSTM[k].fwd_pass();\n",
    "                        self.fg[k][j] = f;\n",
    "                        self.ig[k][j] = i;\n",
    "                        self.og[k][j] = o;\n",
    "                        self.mc[k][j] = m; # memory cell, aka cell state\n",
    "                        self.cs[k][j] = c;\n",
    "                        self.hs[k][j] = h;  \n",
    "                        \n",
    "                # output layer - may replace with softmax instead\n",
    "                self.ys[j] = sigmoid(np.dot(self.W,self.hs[numHiddenLayer-1][j]));\n",
    "                tmp = softmax(self.ys[j]);\n",
    "                char_idx = np.argmax(self.targets[j]);\n",
    "                errSum += -np.log(tmp[char_idx]);  \n",
    "                \n",
    "            return errSum;               \n",
    "        else:\n",
    "            # bidirectional learning\n",
    "            \n",
    "            \n",
    "            return\n",
    "    \n",
    "    def bwd_pass(self):        \n",
    "        \n",
    "        #errSum = 0;\n",
    "        \n",
    "        c_grads  = np.zeros((self.numHiddenLayer,self.sizeHidden));\n",
    "        h_grads  = np.zeros((self.numHiddenLayer,self.sizeHidden));\n",
    "        \n",
    "        W_grad   = np.zeros((self.lenOut,self.sizeHidden));\n",
    "        Ob_grad  = np.zeros(self.lenOut);    \n",
    "        \n",
    "        xf_grad   = np.zeros((self.sizeHidden,self.LSTM[0].lenIn));\n",
    "        xi_grad   = np.zeros((self.sizeHidden,self.LSTM[0].lenIn));\n",
    "        xm_grad   = np.zeros((self.sizeHidden,self.LSTM[0].lenIn));\n",
    "        xo_grad   = np.zeros((self.sizeHidden,self.LSTM[0].lenIn));\n",
    "        \n",
    "        hf_grad   = np.zeros((self.sizeHidden,self.sizeHidden));\n",
    "        hi_grad   = np.zeros((self.sizeHidden,self.sizeHidden));\n",
    "        hm_grad   = np.zeros((self.sizeHidden,self.sizeHidden));\n",
    "        ho_grad   = np.zeros((self.sizeHidden,self.sizeHidden));\n",
    "        \n",
    "        fb_grad   = np.zeros(self.sizeHidden)\n",
    "        ib_grad   = np.zeros(self.sizeHidden)\n",
    "        mb_grad   = np.zeros(self.sizeHidden)\n",
    "        ob_grad   = np.zeros(self.sizeHidden)\n",
    "        \n",
    "        \n",
    "        if(self.biDir == 0): \n",
    "            \n",
    "            if(numHiddenLayer > 1):\n",
    "                xf_grads = np.zeros((numHiddenLayer-1,self.sizeHidden,self.sizeHidden));\n",
    "                xi_grads = np.zeros((numHiddenLayer-1,self.sizeHidden,self.sizeHidden));\n",
    "                xm_grads = np.zeros((numHiddenLayer-1,self.sizeHidden,self.sizeHidden));\n",
    "                xo_grads = np.zeros((numHiddenLayer-1,self.sizeHidden,self.sizeHidden));\n",
    "                \n",
    "                hf_grads = np.zeros((numHiddenLayer-1,self.sizeHidden,self.sizeHidden));\n",
    "                hi_grads = np.zeros((numHiddenLayer-1,self.sizeHidden,self.sizeHidden));\n",
    "                hm_grads = np.zeros((numHiddenLayer-1,self.sizeHidden,self.sizeHidden));\n",
    "                ho_grads = np.zeros((numHiddenLayer-1,self.sizeHidden,self.sizeHidden));    \n",
    "                \n",
    "                fb_grads = np.zeros((numHiddenLayer-1,self.sizeHidden));\n",
    "                ib_grads = np.zeros((numHiddenLayer-1,self.sizeHidden));\n",
    "                mb_grads = np.zeros((numHiddenLayer-1,self.sizeHidden));\n",
    "                ob_grads = np.zeros((numHiddenLayer-1,self.sizeHidden));                \n",
    "                    \n",
    "            # propagates through time and layers\n",
    "            for j in range(self.lenRec,-1,-1):\n",
    "                # output to last hidden\n",
    "                err = self.targets[j] - self.ys[j];\n",
    "                \n",
    "                \n",
    "                W_grad += np.dot((np.atleast_2d(err*sigmoid_deriv(self.ys[j])).T),np.atleast_2d(self.hs[numHiddenLayer-1][j]));\n",
    "                #print(W_grad)\n",
    "                err = np.dot(self.W.T, err);\n",
    "                \n",
    "                for k in reversed(range(1,numHiddenLayer)):\n",
    "                    # setup LSTM propagation parameters\n",
    "                    self.LSTM[k].x = self.hs[k-1][j];\n",
    "                    self.LSTM[k].ph= self.hs[k][j-1];\n",
    "                    self.LSTM[k].c = self.cs[k][j];\n",
    "                    \n",
    "                    xf,xi,xm,xo,\\\n",
    "                    hf,hi,hm,ho,c_grads[k],h_grads[k],\\\n",
    "                    df,di,dm,do = \\\n",
    "                    self.LSTM[k].bwd_pass(err, self.cs[k][j-1],self.fg[k][j],self.ig[k][j],self.mc[k][j],self.og[k][j],\\\n",
    "                                         c_grads[k], h_grads[k]);\n",
    "                                      \n",
    "                    xf_grads[k-1] +=  xf;\n",
    "                    xi_grads[k-1] +=  xi;  \n",
    "                    xm_grads[k-1] +=  xm;  \n",
    "                    xo_grads[k-1] +=  xo;  \n",
    "                    hf_grads[k-1] +=  hf;  \n",
    "                    hi_grads[k-1] +=  hi;  \n",
    "                    hm_grads[k-1] +=  hm;  \n",
    "                    ho_grads[k-1] +=  ho;  \n",
    "                    fb_grads[k-1] +=  df;\n",
    "                    ib_grads[k-1] +=  di;\n",
    "                    mb_grads[k-1] +=  dm;\n",
    "                    ob_grads[k-1] +=  do;\n",
    "\n",
    "                    err = np.dot(self.LSTM[k].xfW, df) + np.dot(self.LSTM[k].xiW, di) +\\\n",
    "                          np.dot(self.LSTM[k].xoW, do) + np.dot(self.LSTM[k].xmW, dm);\n",
    "                \n",
    "                self.LSTM[0].x = self.xs[j];\n",
    "                self.LSTM[0].ph= self.hs[0][j-1];\n",
    "                self.LSTM[0].c = self.cs[0][j];\n",
    "\n",
    "                xf,xi,xm,xo,\\\n",
    "                hf,hi,hm,ho,c_grads[0],h_grads[0],\\\n",
    "                df,di,dm,do = \\\n",
    "                self.LSTM[0].bwd_pass(err, self.cs[0][j-1],self.fg[0][j],self.ig[0][j],self.mc[0][j],self.og[0][j],\\\n",
    "                                     c_grads[0], h_grads[0]);\n",
    "\n",
    "                xf_grad +=  xf;\n",
    "                xi_grad +=  xi;  \n",
    "                xm_grad +=  xm;  \n",
    "                xo_grad +=  xo;  \n",
    "                hf_grad +=  hf;  \n",
    "                hi_grad +=  hi;  \n",
    "                hm_grad +=  hm;  \n",
    "                ho_grad +=  ho;  \n",
    "                fb_grad +=  df;\n",
    "                ib_grad +=  di;\n",
    "                mb_grad +=  dm;\n",
    "                ob_grad +=  do;\n",
    "                \n",
    "            \n",
    "            # update using RMSprop\n",
    "            for k in range(1,numHiddenLayer):\n",
    "                self.LSTM[k].update(xf_grads[k-1]/self.lenRec, xi_grads[k-1]/self.lenRec, \\\n",
    "                                   xm_grads[k-1]/self.lenRec, xo_grads[k-1]/self.lenRec, \\\n",
    "                                   hf_grads[k-1]/self.lenRec, hi_grads[k-1]/self.lenRec, \\\n",
    "                                   hm_grads[k-1]/self.lenRec, ho_grads[k-1]/self.lenRec, \\\n",
    "                                   fb_grads[k-1]/self.lenRec, ib_grads[k-1]/self.lenRec, \\\n",
    "                                   mb_grads[k-1]/self.lenRec, ob_grads[k-1]/self.lenRec,\n",
    "                                   );\n",
    "            self.LSTM[0].update(xf_grad/self.lenRec, xi_grad/self.lenRec, \\\n",
    "                               xm_grad/self.lenRec, xo_grad/self.lenRec, \\\n",
    "                               hf_grad/self.lenRec, hi_grad/self.lenRec, \\\n",
    "                               hm_grad/self.lenRec, ho_grad/self.lenRec,\\\n",
    "                               fb_grad/self.lenRec, ib_grad/self.lenRec, \\\n",
    "                               mb_grad/self.lenRec, ob_grad/self.lenRec);\n",
    "            \n",
    "            \n",
    "            self.update(W_grad/self.lenRec);\n",
    "            \n",
    "          \n",
    "            \n",
    "    def update(self, W_grad):\n",
    "        self.GW = 0.9*self.GW + 0.1*W_grad**2;\n",
    "        self.W -= self.learningRate/np.sqrt(self.GW + 1e-8) * W_grad;\n",
    "\n",
    "    def sample(self,inputs):\n",
    "        if(self.biDir == 0):          \n",
    "\n",
    "            # update input\n",
    "            self.x    = inputs;\n",
    "            # first layer\n",
    "            self.LSTM[0].x = self.x;\n",
    "            #print(self.x.shape)\n",
    "            self.LSTM[0].ph= self.hs[0][0];\n",
    "            c, h, f, i, m, o = self.LSTM[0].fwd_pass();\n",
    "            self.fg[0][1] = f;\n",
    "            self.ig[0][1] = i;\n",
    "            self.og[0][1] = o;\n",
    "            self.mc[0][1] = m;\n",
    "            self.cs[0][1] = c;\n",
    "            self.hs[0][1] = h;\n",
    "\n",
    "            # other layers\n",
    "            if(self.numHiddenLayer > 1):\n",
    "                for k in range(1,numHiddenLayer):\n",
    "                    self.LSTM[k].x = self.hs[k-1][1];\n",
    "                    self.LSTM[k].ph= self.hs[k][0];\n",
    "                    c, h, f, i, m, o = self.LSTM[k].fwd_pass();\n",
    "                    self.fg[k][1] = f;\n",
    "                    self.ig[k][1] = i;\n",
    "                    self.og[k][1] = o;\n",
    "                    self.mc[k][1] = m; # memory cell, aka cell state\n",
    "                    self.cs[k][1] = c;\n",
    "                    self.hs[k][1] = h;  \n",
    "\n",
    "            # output layer - may replace with softmax instead\n",
    "            self.ys[1] = sigmoid(np.dot(self.W,self.hs[numHiddenLayer-1][1]));\n",
    "            #print(self.W)\n",
    "            maxIdx = np.argmax(self.ys[1])\n",
    "            return maxIdx;\n",
    "\n",
    "        else:\n",
    "            # bidirectional learning         \n",
    "            return    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM:\n",
    "    \n",
    "    def __init__ (self,lenIn,sizeHidden,lenRec,learningRate):\n",
    "        self.lenIn        = lenIn\n",
    "        self.sizeHidden   = sizeHidden\n",
    "        self.lenRec       = lenRec\n",
    "        self.learningRate = learningRate\n",
    "        \n",
    "        # x is x and h horizontally stacked together [x]\n",
    "        self.x = np.zeros(lenIn)\n",
    "        self.ph= np.zeros(sizeHidden)\n",
    "        self.h = np.zeros(sizeHidden)\n",
    "        self.c = np.zeros(sizeHidden)\n",
    "        \n",
    "        # Weight matrices\n",
    "        self.xfW = np.random.random((sizeHidden,lenIn));\n",
    "        self.xiW = np.random.random((sizeHidden,lenIn));\n",
    "        self.xoW = np.random.random((sizeHidden,lenIn));\n",
    "        self.xmW = np.random.random((sizeHidden,lenIn)); # cell state matrix(it is also a gate)\n",
    "        \n",
    "        self.hfW = np.random.random((sizeHidden,sizeHidden));\n",
    "        self.hiW = np.random.random((sizeHidden,sizeHidden));\n",
    "        self.hoW = np.random.random((sizeHidden,sizeHidden));\n",
    "        self.hmW = np.random.random((sizeHidden,sizeHidden));       \n",
    "                \n",
    "        # biases\n",
    "        self.fb = np.zeros(sizeHidden);\n",
    "        self.ib = np.zeros(sizeHidden); \n",
    "        self.ob = np.zeros(sizeHidden); \n",
    "        self.mb = np.zeros(sizeHidden); \n",
    "        \n",
    "        # for RMSprop only\n",
    "        self.GxfW = np.random.random((sizeHidden,lenIn));\n",
    "        self.GxiW = np.random.random((sizeHidden,lenIn));\n",
    "        self.GxoW = np.random.random((sizeHidden,lenIn));\n",
    "        self.GxmW = np.random.random((sizeHidden,lenIn));\n",
    "        \n",
    "        self.GhfW = np.random.random((sizeHidden,sizeHidden));\n",
    "        self.GhiW = np.random.random((sizeHidden,sizeHidden));\n",
    "        self.GhoW = np.random.random((sizeHidden,sizeHidden));\n",
    "        self.GhmW = np.random.random((sizeHidden,sizeHidden));         \n",
    "              \n",
    "        self.Gfb = np.zeros(sizeHidden);\n",
    "        self.Gib = np.zeros(sizeHidden); \n",
    "        self.Gob = np.zeros(sizeHidden); \n",
    "        self.Gmb = np.zeros(sizeHidden);         \n",
    "             \n",
    "        \n",
    "    def fwd_pass(self):\n",
    "        #print(self.x.shape)\n",
    "        f       = sigmoid(np.dot(self.xfW, self.x) + np.dot(self.hfW, self.ph) + self.fb)\n",
    "        self.c *= f\n",
    "        i       = sigmoid(np.dot(self.xiW, self.x) + np.dot(self.hiW, self.ph) + self.ib)\n",
    "        m       = tanh(np.dot(self.xmW, self.x)    + np.dot(self.hmW, self.ph) + self.mb)\n",
    "        self.c += i * m\n",
    "        o       = sigmoid(np.dot(self.xoW, self.x) + np.dot(self.hoW, self.ph)  + self.ob)\n",
    "        self.h  = o * tanh(self.c)\n",
    "        \n",
    "        return self.c, self.h, f, i, m, o;\n",
    "    \n",
    "    def bwd_pass(self,error, prev_c, f, i, m, o, c_g, h_g):\n",
    "        \n",
    "        error = np.clip(error + h_g, -6, 6);\n",
    "        \n",
    "        do = tanh(self.c) * error;\n",
    "        xo = np.dot(np.atleast_2d(do*tanh_deriv(o)).T, np.atleast_2d(self.x));\n",
    "        ho = np.dot(np.atleast_2d(do*tanh_deriv(o)).T, np.atleast_2d(self.ph));\n",
    "        \n",
    "        dcs= np.clip(error*o* tanh_deriv(self.c) + c_g,-6, 6);\n",
    "        dm = dcs * i;\n",
    "        xm = np.dot(np.atleast_2d(dm * tanh_deriv(m)).T, np.atleast_2d(self.x));\n",
    "        hm = np.dot(np.atleast_2d(dm * tanh_deriv(m)).T, np.atleast_2d(self.ph));\n",
    "        \n",
    "        di = dcs * m;\n",
    "        xi = np.dot(np.atleast_2d(dm * sigmoid_deriv(m)).T, np.atleast_2d(self.x));\n",
    "        hi = np.dot(np.atleast_2d(dm * sigmoid_deriv(m)).T, np.atleast_2d(self.ph));\n",
    "        \n",
    "        df = dcs * f;\n",
    "        xf = np.dot(np.atleast_2d(dm * sigmoid_deriv(f)).T, np.atleast_2d(self.x));\n",
    "        hf = np.dot(np.atleast_2d(dm * sigmoid_deriv(f)).T, np.atleast_2d(self.ph));\n",
    "        \n",
    "        c_grad = dcs * f;\n",
    "        h_grad = np.dot(self.hfW, df) + np.dot(self.hiW, di) +\\\n",
    "                          np.dot(self.hoW, do) + np.dot(self.hmW, dm);\n",
    "        \n",
    "        \n",
    "        return xf,xi,xm,xo, hf,hi,hm,ho, c_grad,h_grad, df,di,dm,do;\n",
    "    \n",
    "    def update(self, xf, xi, xm, xo, hf, hi, hm, ho, fb, ib, mb, ob):\n",
    "\n",
    "        self.GxfW = 0.9*self.GxfW + 0.1*xf**2;\n",
    "        self.GxiW = 0.9*self.GxiW + 0.1*xi**2;\n",
    "        self.GxoW = 0.9*self.GxoW + 0.1*xo**2;\n",
    "        self.GxmW = 0.9*self.GxmW + 0.1*xm**2;\n",
    "        self.GhfW = 0.9*self.GhfW + 0.1*hf**2;\n",
    "        self.GhiW = 0.9*self.GhiW + 0.1*hi**2;\n",
    "        self.GhoW = 0.9*self.GhoW + 0.1*ho**2;\n",
    "        self.GhmW = 0.9*self.GhmW + 0.1*hm**2;\n",
    "        self.Gfb  = 0.9*self.Gfb  + 0.1*fb**2;\n",
    "        self.Gib  = 0.9*self.Gib  + 0.1*ib**2;\n",
    "        self.Gmb  = 0.9*self.Gmb  + 0.1*mb**2;\n",
    "        self.Gob  = 0.9*self.Gob  + 0.1*ob**2;\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "inp = np.zeros((5,10))\n",
    "tar = np.zeros((5,10))\n",
    "lenIn, lenOut, lenRec, sizeHidden, numHiddenLayer, inputs,targets, learningRate, biDir = 10,10,5,8,1,inp,tar,0.1,0;\n",
    "R = myRNN(lenIn, lenOut, lenRec, sizeHidden, numHiddenLayer,inputs, targets, learningRate, biDir=0)\n",
    "\n",
    "R.fwd_pass()\n",
    "\n",
    "R.bwd_pass()\n",
    "\n",
    "\n",
    "\n",
    "print(R.LSTM[0].lenIn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "431677 ,  79\n",
      "{'9': 0, '?': 1, 'e': 2, '*': 3, ':': 4, 'c': 5, 'n': 6, 'L': 7, '~': 8, 'X': 9, 'u': 10, 'S': 11, 'd': 12, 'T': 13, 'o': 14, 'm': 15, 'Q': 16, '\\n': 17, '0': 18, '\\\\': 19, '\"': 20, '2': 21, 'N': 22, 'C': 23, 'B': 24, 'M': 25, '7': 26, '4': 27, 'y': 28, '!': 29, 'b': 30, 'H': 31, 's': 32, 'v': 33, '\\t': 34, \"'\": 35, 'p': 36, 'D': 37, 'j': 38, '3': 39, '(': 40, 'P': 41, 'Y': 42, 'g': 43, '1': 44, 'Z': 45, 'k': 46, 'z': 47, 'a': 48, 'R': 49, 'F': 50, 'E': 51, 'J': 52, '8': 53, 'h': 54, 'K': 55, 'q': 56, ' ': 57, '.': 58, 't': 59, 'A': 60, 'G': 61, '-': 62, '5': 63, 'f': 64, 'x': 65, 'U': 66, 'W': 67, 'r': 68, 'O': 69, 'l': 70, ',': 71, 'w': 72, '6': 73, 'I': 74, 'i': 75, ')': 76, 'V': 77, ';': 78}\n",
      "{0: '9', 1: '?', 2: 'e', 3: '*', 4: ':', 5: 'c', 6: 'n', 7: 'L', 8: '~', 9: 'X', 10: 'u', 11: 'S', 12: 'd', 13: 'T', 14: 'o', 15: 'm', 16: 'Q', 17: '\\n', 18: '0', 19: '\\\\', 20: '\"', 21: '2', 22: 'N', 23: 'C', 24: 'B', 25: 'M', 26: '7', 27: '4', 28: 'y', 29: '!', 30: 'b', 31: 'H', 32: 's', 33: 'v', 34: '\\t', 35: \"'\", 36: 'p', 37: 'D', 38: 'j', 39: '3', 40: '(', 41: 'P', 42: 'Y', 43: 'g', 44: '1', 45: 'Z', 46: 'k', 47: 'z', 48: 'a', 49: 'R', 50: 'F', 51: 'E', 52: 'J', 53: '8', 54: 'h', 55: 'K', 56: 'q', 57: ' ', 58: '.', 59: 't', 60: 'A', 61: 'G', 62: '-', 63: '5', 64: 'f', 65: 'x', 66: 'U', 67: 'W', 68: 'r', 69: 'O', 70: 'l', 71: ',', 72: 'w', 73: '6', 74: 'I', 75: 'i', 76: ')', 77: 'V', 78: ';'}\n"
     ]
    }
   ],
   "source": [
    "data = open('HP1.txt','r', encoding=\"utf8\").read();\n",
    "chars = list(set(data))\n",
    "data_size, vocab_size = len(data), len(chars)\n",
    "print(data_size,\", \",vocab_size)\n",
    "\n",
    "char_to_ix = {ch:i for i, ch in enumerate(chars)}\n",
    "ix_to_char = {i:ch for i,ch in enumerate(chars)}\n",
    "print(char_to_ix)\n",
    "print(ix_to_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(array,num_entry):\n",
    "    xs = np.zeros((len(array),num_entry))\n",
    "    for i in range(len(array)):\n",
    "        xs[i][array[i]] = 1; \n",
    "    return xs;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harry Potter and the Sorc\n",
      "inputs [31, 48, 68, 68, 28, 57, 41, 14, 59, 59, 2, 68, 57, 48, 6, 12, 57, 59, 54, 2, 57, 11, 14, 68, 5]\n",
      "arry Potter and the Sorce\n",
      "targets [48, 68, 68, 28, 57, 41, 14, 59, 59, 2, 68, 57, 48, 6, 12, 57, 59, 54, 2, 57, 11, 14, 68, 5, 2]\n",
      "0 err: 109.2361963116755\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-329-12a072ae9882>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0merr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mR\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfwd_pass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m     \u001b[0mR\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbwd_pass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m1000\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-323-c4047593d906>\u001b[0m in \u001b[0;36mbwd_pass\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    214\u001b[0m                 \u001b[0mxf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mxi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mxm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mxo\u001b[0m\u001b[1;33m,\u001b[0m                \u001b[0mhf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mho\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mc_grads\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mh_grads\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m                \u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdo\u001b[0m \u001b[1;33m=\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbwd_pass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mog\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m                                     \u001b[0mc_grads\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh_grads\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m                 \u001b[0mxf_grad\u001b[0m \u001b[1;33m+=\u001b[0m  \u001b[0mxf\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m                 \u001b[0mxi_grad\u001b[0m \u001b[1;33m+=\u001b[0m  \u001b[0mxi\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m                 \u001b[0mxm_grad\u001b[0m \u001b[1;33m+=\u001b[0m  \u001b[0mxm\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "seq_length,position = 25,0\n",
    "inputs = [char_to_ix[ch] for ch in data[position:position+seq_length]]\n",
    "print(data[position:position+seq_length])\n",
    "print(\"inputs\",inputs)\n",
    "\n",
    "targets = [char_to_ix[ch] for ch in data[position+1:position+seq_length+1]] \n",
    "print(data[position+1:position+seq_length+1])\n",
    "print(\"targets\",targets)\n",
    "\n",
    "n,position = 0,0;\n",
    "epoch = 20*1000;\n",
    "lenIn, lenOut, lenRec = vocab_size,vocab_size, seq_length;\n",
    "sizeHidden, numHiddenLayer = 100,1;\n",
    "learningRate, biDir = 0.1,0;\n",
    "\n",
    "\n",
    "R = myRNN(lenIn, lenOut, lenRec, sizeHidden, numHiddenLayer, encode(inputs,vocab_size),encode(targets,vocab_size), learningRate, biDir=0)\n",
    "\n",
    "# training\n",
    "while n<epoch:\n",
    "    \n",
    "    if(position+seq_length+1 >= len(data) or n == 0):\n",
    "        position = 0;\n",
    "        \n",
    "    inputs = [char_to_ix[ch] for ch in data[position:position+seq_length]]\n",
    "    targets = [char_to_ix[ch] for ch in data[position+1:position+seq_length+1]] \n",
    "    \n",
    "    R.update_inputs_targets(encode(inputs,vocab_size),encode(targets,vocab_size));\n",
    "    \n",
    "    err = R.fwd_pass();\n",
    "    \n",
    "    R.bwd_pass();\n",
    "    \n",
    "    if(n%1000 == 0):\n",
    "        print(n,\"err:\",err)\n",
    "        seeds = encode(inputs,vocab_size);\n",
    "        seed = np.array(seeds[0])\n",
    "        for i in range(100):\n",
    "            #print(seed.shape)\n",
    "            ret = R.sample(seed);\n",
    "            #print(ret);\n",
    "            seed = np.zeros_like(seed);\n",
    "            seed[ret] = 1;\n",
    "            \n",
    "\n",
    "    position += seq_length;\n",
    "    position += seq_length;\n",
    "    n += 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
