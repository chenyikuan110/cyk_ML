{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "# Helper functions\n",
    "def softmax(array):\n",
    "    return np.exp(array)/ np.sum(np.exp(array)) # return an array\n",
    "\n",
    "def sigmoid(x):\n",
    "    return (1/(1+np.exp(-x)))\n",
    "\n",
    "def sigmoid_deriv(y):\n",
    "    return (y*(1-y))\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def tanh_deriv(y):\n",
    "    return 1 - pow(np.tanh(y),2)\n",
    "\n",
    "# RNN\n",
    "class basicRNN:\n",
    "    \n",
    "    def __init__ (self, lenIn, lenOut, lenRec, sizeHidden, inputs_encoded, targets, learningRate):\n",
    "        \n",
    "        # Hyper parameters\n",
    "        self.lenIn          = lenIn\n",
    "        self.lenOut         = lenOut\n",
    "        self.lenRec         = lenRec\n",
    "        self.sizeHidden     = sizeHidden\n",
    "        self.learningRate   = learningRate\n",
    "        \n",
    "        # input & expected output\n",
    "        self.inputs_encoded = inputs_encoded;\n",
    "        self.targets = targets;\n",
    "        \n",
    "        # parameters for inference\n",
    "        self.x  = np.zeros(lenIn)  \n",
    "        self.y  = np.zeros(lenOut)\n",
    "        self.hls_infer = np.zeros((lenRec,sizeHidden))\n",
    "        self.hrs_infer = np.zeros((lenRec,sizeHidden))\n",
    "        \n",
    "        self.W  = np.zeros((lenOut,sizeHidden*2)) # for the last fully connected layer\n",
    "        self.b  = np.zeros(lenOut)\n",
    "       \n",
    "        # for training phase \n",
    "        self.xs = np.zeros((lenRec,lenIn))\n",
    "        self.ys = np.zeros((lenRec,lenOut))\n",
    "        self.hls = np.zeros((lenRec,sizeHidden))\n",
    "        self.hrs = np.zeros((lenRec,sizeHidden))\n",
    "        self.GW = np.zeros((lenOut,sizeHidden*2)) # Gradient, for W-update using RMSprop\n",
    "        self.Gb = np.zeros(lenOut)\n",
    "        \n",
    "        # CELL class\n",
    "        self.RNN_cell = RNN_cell(sizeHidden+lenIn,sizeHidden,lenRec,learningRate)\n",
    "        \n",
    "        ''' end of basicRNN.__init__ '''\n",
    "       \n",
    "    ''' This is used when mini-batch is used '''            \n",
    "    def update_inputs_targets(self, inputs_encoded, targets):\n",
    "        self.inputs_encoded  = inputs_encoded\n",
    "        self.targets         = targets\n",
    "    \n",
    "    def fwd_pass(self): \n",
    "        # fwd layer\n",
    "        prev_h = np.zeros_like(self.hls[0])\n",
    "        for t in range(0,self.lenRec):\n",
    "            # update input\n",
    "            self.x    = self.inputs_encoded[t]\n",
    "            self.xs[t]= self.inputs_encoded[t]\n",
    "            \n",
    "            self.RNN_cell.hlx = np.hstack((prev_h, self.x));\n",
    "           \n",
    "            hl = self.RNN_cell.fwd_pass_L()\n",
    "            # bookkeeping\n",
    "            self.hls[t] = hl\n",
    "            prev_h = self.hls[t]\n",
    "                           \n",
    "        # bwd layer\n",
    "        prev_h = np.zeros_like(self.hrs[0])                 \n",
    "        for t in reversed(range(0,self.lenRec)):\n",
    "            # update input\n",
    "            self.x    = self.xs[t]\n",
    "            self.RNN_cell.hrx = np.hstack((prev_h, self.x));\n",
    "           \n",
    "            hr = self.RNN_cell.fwd_pass_R()\n",
    "            # bookkeeping\n",
    "            self.hrs[t] = hr\n",
    "            prev_h = self.hrs[t] \n",
    "                           \n",
    "            # output layer - fully connected layer\n",
    "            self.ys[t] = np.dot(self.W,np.hstack((self.hls[t],self.hrs[t]))) + self.b            \n",
    "        return;              \n",
    "    \n",
    "    def bwd_pass(self):        \n",
    "\n",
    "        avg_loss = 0; # using cross entropy average\n",
    "        h2next_grad  = np.zeros(self.sizeHidden)\n",
    "        \n",
    "        # output bp\n",
    "        W_grad   = np.zeros((self.lenOut,self.sizeHidden*2))\n",
    "        b_grad  = np.zeros(self.lenOut)\n",
    "                                \n",
    "        hlxW_grad  = np.zeros((self.sizeHidden,self.RNN_cell.lenIn));\n",
    "        hrxW_grad  = np.zeros((self.sizeHidden,self.RNN_cell.lenIn));                        \n",
    "        hlb_grad   = np.zeros((self.sizeHidden));\n",
    "        hrb_grad   = np.zeros((self.sizeHidden)); \n",
    "                                \n",
    "        # propagates through time and layers      \n",
    "        dh = np.zeros((lenRec,sizeHidden*2))                \n",
    "\n",
    "        for t in reversed(range(0,self.lenRec)):\n",
    "            \n",
    "            prob = softmax(self.ys[t]) # prevent zero\n",
    "            prob_fix  = prob + 1e-9\n",
    "\n",
    "            # cross entropy\n",
    "            err       = np.log(prob_fix[self.targets[t]])\n",
    "            avg_loss += err\n",
    "     \n",
    "            dy = copy.deepcopy(prob)\n",
    "            dy[self.targets[t]] -= 1\n",
    "            \n",
    "            W_grad += np.dot((np.atleast_2d(dy)).T,np.atleast_2d(np.hstack((self.hls[t],self.hrs[t])) ))\n",
    "            b_grad += dy\n",
    "            \n",
    "            dh[t] = np.dot(self.W.T,dy) \n",
    "                                \n",
    "        for t in reversed(range(0,self.lenRec)):                 \n",
    "            dhl = dh[t,:self.sizeHidden] + h2next_grad         \n",
    "            x_grad  = np.zeros(self.lenIn)\n",
    "            \n",
    "            if(t > 0):\n",
    "                prev_h = self.hls[t-1]\n",
    "            else:\n",
    "                prev_h = np.zeros_like(self.hls[0])\n",
    "                \n",
    "            self.RNN_cell.hlx = np.hstack((prev_h,self.xs[t]))\n",
    "            self.RNN_cell.hl  = self.hls[t]\n",
    "\n",
    "            dhlxW, dhlb, h2next_grad,x_grad = \\\n",
    "            self.RNN_cell.bwd_pass_L( dhl );\n",
    "            \n",
    "            hlxW_grad  +=  dhlxW\n",
    "            hlb_grad   +=  dhlb\n",
    "                                \n",
    "        h2next_grad  = np.zeros(self.sizeHidden)                        \n",
    "        for t in range(0,self.lenRec):                 \n",
    "            dhr = dh[t,self.sizeHidden:] + h2next_grad         \n",
    "            x_grad  = np.zeros(self.lenIn)\n",
    "            \n",
    "            if(t < self.lenRec-1):\n",
    "                prev_h = self.hrs[t+1]\n",
    "            else:\n",
    "                prev_h = np.zeros_like(self.hrs[0])\n",
    "                \n",
    "            self.RNN_cell.hrx = np.hstack((prev_h,self.xs[t]))\n",
    "            self.RNN_cell.hr  = self.hrs[t]\n",
    "\n",
    "            dhrxW, dhrb, h2next_grad,x_grad = \\\n",
    "            self.RNN_cell.bwd_pass_R( dhr );\n",
    "            \n",
    "            hrxW_grad  +=  dhrxW\n",
    "            hrb_grad   +=  dhrb\n",
    "                                \n",
    "        self.RNN_cell.update(hlxW_grad/self.lenRec, hlb_grad/self.lenRec,hrxW_grad/self.lenRec, hrb_grad/self.lenRec);\n",
    "        \n",
    "        self.update(W_grad/self.lenRec,b_grad/self.lenRec);\n",
    "        return avg_loss/self.lenRec;\n",
    "            \n",
    "    def update(self, W_grad, b_grad):\n",
    "        self.GW = self.GW + W_grad**2;\n",
    "        self.W -= self.learningRate/np.sqrt(self.GW + 1e-8) * W_grad;\n",
    "        self.Gb = self.Gb + b_grad**2;\n",
    "        self.b -= self.learningRate/np.sqrt(self.Gb + 1e-8) * b_grad;\n",
    "\n",
    "    def inference(self,xs):\n",
    "        # fwd layer\n",
    "        prev_h = np.zeros_like(self.hls_infer[0])\n",
    "        for t in range(0,self.lenRec):\n",
    "            # update input\n",
    "            self.x    = xs[t]\n",
    "            \n",
    "            self.RNN_cell.hlx = np.hstack((prev_h, self.x));\n",
    "           \n",
    "            hl = self.RNN_cell.fwd_pass_L()\n",
    "            # bookkeeping\n",
    "            self.hls_infer[t] = hl\n",
    "            prev_h = self.hls_infer[t]\n",
    "                           \n",
    "        # bwd layer\n",
    "        prev_h = np.zeros_like(self.hrs[0])                 \n",
    "        for t in reversed(range(0,self.lenRec)):\n",
    "            # update input\n",
    "            self.x    = xs[t]\n",
    "            self.RNN_cell.hrx = np.hstack((prev_h, self.x));\n",
    "           \n",
    "            hr = self.RNN_cell.fwd_pass_R()\n",
    "            # bookkeeping\n",
    "            self.hrs_infer[t] = hr\n",
    "            prev_h = self.hrs_infer[t] \n",
    "                           \n",
    "            # output layer - fully connected layer\n",
    "        y = np.dot(self.W,np.hstack((self.hls_infer[0],self.hrs_infer[0]))) + self.b \n",
    "        p = softmax(y)\n",
    "             \n",
    "        return np.random.choice(range(self.lenIn), p=p.ravel())\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RNN_cell:\n",
    "    \n",
    "    def __init__ (self,lenIn,sizeHidden,lenRec,learningRate):\n",
    "        self.lenIn        = lenIn\n",
    "        self.sizeHidden   = sizeHidden\n",
    "        self.lenRec       = lenRec\n",
    "        self.learningRate = learningRate\n",
    "        \n",
    "        # hx == x is x and h horizontally stacked together\n",
    "        self.hlx = np.zeros(lenIn)\n",
    "        self.hrx = np.zeros(lenIn)\n",
    "        self.hl = np.zeros(sizeHidden)\n",
    "        self.hr = np.zeros(sizeHidden)\n",
    "        \n",
    "        # Weight matrices\n",
    "        self.hlxW = np.random.random((sizeHidden,lenIn));\n",
    "        self.hrxW = np.random.random((sizeHidden,lenIn));\n",
    "        \n",
    "        # biases\n",
    "        self.hlb = np.zeros(sizeHidden);\n",
    "        self.hrb = np.zeros(sizeHidden);\n",
    "        \n",
    "        # for RMSprop only\n",
    "        self.GhlxW = np.random.random((sizeHidden,lenIn));\n",
    "        self.GhrxW = np.random.random((sizeHidden,lenIn));\n",
    "        self.Ghlb = np.zeros(sizeHidden);\n",
    "        self.Ghrb = np.zeros(sizeHidden);\n",
    "        \n",
    "        ''' end of RNN_cell.__init__ '''\n",
    "        \n",
    "    def fwd_pass_L(self):\n",
    "        self.hl = tanh(np.dot(self.hlxW, self.hlx) + self.hlb)       \n",
    "        return self.hl;\n",
    "\n",
    "    def fwd_pass_R(self):\n",
    "        self.hr = tanh(np.dot(self.hrxW, self.hrx) + self.hrb)       \n",
    "        return self.hr;\n",
    "\n",
    "    def bwd_pass_L(self, dhl):\n",
    "        \n",
    "        dhl = np.clip(dhl, -6, 6);       \n",
    "        # h = o*tanh(c)\n",
    "        dhl  = tanh_deriv(self.hl) * dhl\n",
    "        dhlb = dhl\n",
    "        dhlxW = np.dot((np.atleast_2d(dhl)).T,np.atleast_2d(self.hlx)) \n",
    "        \n",
    "        hlx_grad = np.dot(self.hlxW.T, dhl)\n",
    "               \n",
    "        return dhlxW, dhlb, hlx_grad[:self.sizeHidden],hlx_grad[self.sizeHidden:];\n",
    "\n",
    "    def bwd_pass_R(self, dhr):\n",
    "        \n",
    "        dhr = np.clip(dhr, -6, 6);       \n",
    "        # h = o*tanh(c)\n",
    "        dhr  = tanh_deriv(self.hr) * dhr\n",
    "        dhrb = dhr\n",
    "        dhrxW = np.dot((np.atleast_2d(dhr)).T,np.atleast_2d(self.hrx)) \n",
    "        \n",
    "        hrx_grad = np.dot(self.hrxW.T, dhr)\n",
    "               \n",
    "        return dhrxW, dhrb, hrx_grad[:self.sizeHidden],hrx_grad[self.sizeHidden:];\n",
    "    \n",
    "    def update(self, hlxW_grad, hlb_grad, hrxW_grad, hrb_grad):\n",
    "\n",
    "        # adagrad\n",
    "        self.GhlxW = self.GhlxW + hlxW_grad**2\n",
    "        self.Ghlb = self.Ghlb + hlb_grad**2\n",
    "        self.GhrxW = self.GhrxW + hrxW_grad**2\n",
    "        self.Ghrb = self.Ghrb + hrb_grad**2\n",
    "        \n",
    "        self.hlxW -= self.learningRate/np.sqrt(self.GhlxW + 1e-8) * hlxW_grad\n",
    "        self.hlb -= self.learningRate/np.sqrt(self.Ghlb + 1e-8) * hlb_grad\n",
    "        self.hrxW -= self.learningRate/np.sqrt(self.GhrxW + 1e-8) * hrxW_grad\n",
    "        self.hrb -= self.learningRate/np.sqrt(self.Ghrb + 1e-8) * hrb_grad\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "431677 ,  79\n",
      "{'S': 0, '9': 1, '\\\\': 2, 'H': 3, '.': 4, ',': 5, 'z': 6, 'A': 7, '4': 8, '?': 9, '\"': 10, '3': 11, '5': 12, 'c': 13, 'h': 14, 'W': 15, 'Y': 16, 'I': 17, 'u': 18, 'i': 19, 'a': 20, ';': 21, 'X': 22, 'n': 23, 'r': 24, 'l': 25, 'Q': 26, '0': 27, \"'\": 28, 's': 29, '!': 30, '~': 31, '8': 32, 'T': 33, 'D': 34, ' ': 35, 'v': 36, 'q': 37, 'Z': 38, 'C': 39, '-': 40, 'R': 41, 'k': 42, 'F': 43, 'b': 44, 'B': 45, 'j': 46, 'J': 47, 'y': 48, 'e': 49, 'L': 50, '6': 51, 'G': 52, 'U': 53, '1': 54, 't': 55, '2': 56, 'g': 57, '\\t': 58, 'P': 59, 'o': 60, 'E': 61, 'O': 62, 'N': 63, '\\n': 64, 'V': 65, 'd': 66, 'M': 67, 'K': 68, '(': 69, ':': 70, '7': 71, 'w': 72, '*': 73, 'm': 74, 'f': 75, 'x': 76, 'p': 77, ')': 78}\n",
      "{0: 'S', 1: '9', 2: '\\\\', 3: 'H', 4: '.', 5: ',', 6: 'z', 7: 'A', 8: '4', 9: '?', 10: '\"', 11: '3', 12: '5', 13: 'c', 14: 'h', 15: 'W', 16: 'Y', 17: 'I', 18: 'u', 19: 'i', 20: 'a', 21: ';', 22: 'X', 23: 'n', 24: 'r', 25: 'l', 26: 'Q', 27: '0', 28: \"'\", 29: 's', 30: '!', 31: '~', 32: '8', 33: 'T', 34: 'D', 35: ' ', 36: 'v', 37: 'q', 38: 'Z', 39: 'C', 40: '-', 41: 'R', 42: 'k', 43: 'F', 44: 'b', 45: 'B', 46: 'j', 47: 'J', 48: 'y', 49: 'e', 50: 'L', 51: '6', 52: 'G', 53: 'U', 54: '1', 55: 't', 56: '2', 57: 'g', 58: '\\t', 59: 'P', 60: 'o', 61: 'E', 62: 'O', 63: 'N', 64: '\\n', 65: 'V', 66: 'd', 67: 'M', 68: 'K', 69: '(', 70: ':', 71: '7', 72: 'w', 73: '*', 74: 'm', 75: 'f', 76: 'x', 77: 'p', 78: ')'}\n",
      "Harry Potter and the Sorcerer's Stone\n",
      "CHAPTER ONE\n",
      "THE BOY WHO LIVED\n",
      "Mr. and Mrs. Dursley, of number \n",
      "inputs [3, 20, 24, 24, 48, 35, 59, 60, 55, 55, 49, 24, 35, 20, 23, 66, 35, 55, 14, 49, 35, 0, 60, 24, 13, 49, 24, 49, 24, 28, 29, 35, 0, 55, 60, 23, 49, 64, 39, 3, 7, 59, 33, 61, 41, 35, 62, 63, 61, 64, 33, 3, 61, 35, 45, 62, 16, 35, 15, 3, 62, 35, 50, 17, 65, 61, 34, 64, 67, 24, 4, 35, 20, 23, 66, 35, 67, 24, 29, 4, 35, 34, 18, 24, 29, 25, 49, 48, 5, 35, 60, 75, 35, 23, 18, 74, 44, 49, 24, 35]\n",
      "arry Potter and the Sorcerer's Stone\n",
      "CHAPTER ONE\n",
      "THE BOY WHO LIVED\n",
      "Mr. and Mrs. Dursley, of number f\n",
      "targets [20, 24, 24, 48, 35, 59, 60, 55, 55, 49, 24, 35, 20, 23, 66, 35, 55, 14, 49, 35, 0, 60, 24, 13, 49, 24, 49, 24, 28, 29, 35, 0, 55, 60, 23, 49, 64, 39, 3, 7, 59, 33, 61, 41, 35, 62, 63, 61, 64, 33, 3, 61, 35, 45, 62, 16, 35, 15, 3, 62, 35, 50, 17, 65, 61, 34, 64, 67, 24, 4, 35, 20, 23, 66, 35, 67, 24, 29, 4, 35, 34, 18, 24, 29, 25, 49, 48, 5, 35, 60, 75, 35, 23, 18, 74, 44, 49, 24, 35, 75]\n",
      "!!!! 431677\n",
      "0 err: -4.369447773467019\n",
      "uEraSuyEHsarto.\n",
      "DTOrdarOTH.n\n",
      "TdaEsrSEPdeEaP PSTSTSDnStTEE\n",
      "dodSrtnrrtyTOnDeErT\n",
      "EdnPTSDoueETDoMaPdrHDo\n",
      "rdsOTESSEts.ny.aeuTDouH\n",
      "eOt tttEesuHrOanOur s DuOMyDS\n",
      "u\n",
      "dSTSoy\n",
      "rsa\n",
      "HdPEO\n",
      "O\n",
      "HPSOOe oyMsePOD.OHHreD a\n",
      "\n",
      "500 err: -3.41026176768785\n",
      "hlHeays \"oadmVtno,neih a tostu eH hnA   yrilih en evdueeomhne r Dtsfe li.rihenihhu nhodlt obruuor, fn\n",
      "r le t \n",
      "geeihgig'yiri the  hbrs o'rnbr\"lelnehdint  io,iyet,pyaitssrHrphmye  ne ofge eOnth f k dsbe\n",
      "\n",
      "1000 err: -2.9818037455345796\n",
      "ap  i alal.hnsn a teoetgmdemhya n,nppofe 't,d tassrcoagoshsotswoao,erdwpaan,eh-isrienh ln aage?toeardrowmagaclofHtgueth ao\" t,i i-noohsre.oa o  \" od udeylH\"o prs  ase pu u:ytnorlasS,tHg y yrehhcnol:ah\n",
      "\n",
      "1500 err: -2.742901390317434\n",
      "kwrsho cnbssmaogoatST da,bautee. li oymvew  dsae str rgDndhw n.Be'hoe a kdebhnh be hu g ssr saeeugc, aeeetf Hitr rNla   aiolargreDswotida.trthhoedofta\n",
      "fteor  \"uht et etesn\n",
      " ayose wthD skeMio shh auoh \n",
      "\n",
      "2000 err: -2.534616076473028\n",
      "ctfftaedo iyesyo ts rila pen\n",
      "t hnbwreE\" ilsanms l n cata tgt t coIl gtf wgnnatda Sthnatieol hmye sne .vuNnooadt t ioat c e yaon t iettar sfhee tih t gys sk wfphaia llltir,nodoiooa inlgyrutlwit  s seoa\n",
      "\n",
      "2500 err: -2.17779890258665\n",
      "uerrutabpaa ndtm.h dafrHehl\n",
      "nk.udehl\n",
      "a hmeddhfe t t \" nI,. vhyIoam\n",
      "dhet hin rfaRhe'dn hgyvnaetdntdehdde nowe gahxlte u: e\n",
      "odesra .ime g shWe-eyihm.god man gk nie tae taSe 'opiagan eusN het o.g algmehe\n",
      "\n",
      "3000 err: -3.002470047366387\n",
      "di Nou  b'ealetuh.tgshu bulaattigbR hro m ieueS sheeia g iot, b,tirRuaufrrI gty hSaahlngr inascar'is\n",
      " roonewteid eohui e trnikiid. pofam\"vee ygwsab' hrbsag ecW wN a aog,gyla,lyah agiatrnolhim rnrauert\n",
      "\n",
      "3500 err: -2.3765408188861747\n",
      "owone?ac f',' lhtt  dt\"tnm' ws ioa i dtke toen nineraI t ser'mehhw fharv A\" s atsn.w yr u.nrii   id shnelar'ay  at-g  aelfa'd\" inawianfywW.s shr ?ttcnNigetwvny vhhiecf eelesahyawahads  o ies'aefafst n\n",
      "\n",
      "4000 err: -2.330107099723382\n",
      "u e, \" m yTerr ssledveer feoyup\n",
      "baiterha,a\" thee im tcr H saa\" ihuisr leoc we \"feys .e \"af eberrG rfoH, f aitoonu -oaebieen bmaekto\"diprm itodri.mdgle thl O sHiloomtrse anaj wer- esg He\" \n",
      "yno s ,e bpH\n",
      "\n",
      "!!!! 431677\n",
      "4500 err: -2.0312644971111955\n",
      " wes 'hos derdyneahme shenfloDwP  uiy rnd eslPnpe , raeen Aloophr he to c w f,omDl P losoghh. 'i, s Da  bpul nel afethef t e\n",
      "gyoul oaferodvd Mrooa e wuc ren.dlo bo\" he jo setafehIoo w dvmevhee btn s u\n",
      "\n",
      "5000 err: -1.6564323216094252\n",
      " thtthteaikd,w bis etetrsod, ew tee orpir mricepwhthhshe t niredet shidhohtm hdituand ve  nopteWa aol mtohefikd\n",
      "d ais efoymsids td bee Drsi, Ctuuemtutouthe t tigeo'r sits tItv huusognd ee haouetso \"ey\n",
      "\n",
      "5500 err: -1.3677251571053293\n",
      "osrin, weosinau Hidexahttar und aftut rot grs y\n",
      "tgnondtrrwr o oekdit ont al utt aarrwmlo h. vi Rwaecltrmt he saeis Tine.dyttit cnd ohtvt pol lrs w fistn,oere. tsfsnd d One tteait uurf.mde hd d. w alad\n",
      "\n",
      "6000 err: -1.5553862431479373\n",
      "goe  lueheris, yraIaMais thn ssc!eaHoiMebaHore dt\" Hoked loimoOlt oe rneal? tou wn nt itad al, \"eruene  lerletos, hr daHais ton Ns?erNuaw e,lcorl aO.igogey toifoulw oe Useala tol wh ng ut-p ale pereen\n",
      "\n",
      "6500 err: -1.5417415673823422\n",
      ", faNlr'ld toucht On th ver..inMeey saor tlkei lowt, \"ypokne. the Iofo uodiddusay wfdufOMur to rontI gaberm.w touwry rn hh vou.fis'ede s\n",
      "or tif\"i l'wyt eyooane. the curo riwiddasay av roeie. b- r,nyri\n",
      "\n",
      "7000 err: -1.1621528368534886\n",
      " warrd Hadermy,iocrpo son'p aot lr as,Hore-\" \"aic \"arrid glsrrre. b\n",
      "haros tonltolt-. thad Ft?\n",
      "n\"S'd oagre daveeyoefaortswsondH a\n",
      "v sz il'toredd \"lgd Harrrm waltale. oowieog sonltist!f b ad IUH;r\"\"ut H\n",
      "\n",
      "7500 err: -0.8909176273010451\n",
      "rabbtchese sinleyd bil she berteaghint thed no mo the Humed\n",
      "\" erfuens. the e um, ate ages araregid vaSbtohebe sinltyd Hisishe metseaphing them n. bo the fimed\n",
      "g eiymessy toe r uno ucy Sney ararmyid Ho\n",
      "\n",
      "8000 err: -1.0443311154132666\n",
      "urfzny.g. it heanc an'er-s Iofing.vs.\"\n",
      "Rin cougee't aet worpeo it, ix wus toowQotd\n",
      "Hgatrty renat, bog,inyrg. it ykan? auxeros R\n",
      "ring.\"s  inie pouveent bdd Porkex au  yt s's toQpmon,\n",
      "\"\n",
      "igrtg resot. tud\n",
      "\n",
      "8500 err: -0.9539880389344861\n",
      "thinrMvldrpwist the sn.a\"\n",
      "\"tor Wod k met tht ttonegouI of the sioruv \" \"wg, no-, wdm klat tou aspopthivr eld\n",
      "swis- the c,dar\n",
      " tor \"od I met thl Htohe oup if the slosas d \"aeo noec a,soglLt.to\" aspomth\n",
      "\n",
      "!!!! 431677\n",
      "9000 err: -1.11544071251377\n",
      " tiborcP re oreryoin shen.po hud Vadreag kboit o to,oritole-s sais HPrurd reyepbem ngsugdensge Her  sikarcw re oreryoin shenuio had iadrear tbeit o tlcorimowe,s aaid hgmugd veyepceroaghugken'ye fer, s\n",
      "\n",
      "9500 err: -0.7653261625964329\n",
      "Df the war  bit it \"nampemwirsHe?g feerde-eoIt hid at, Hagriem on sa.aping the tfat.\n",
      "\"h.nrkdhd sakd f the Iar  bit is'wnar.ipwirshi-e t ersiweopt hud am, HaiWied on sa.\n",
      "panw the t\"\"t. \"hHnr,aip HanH f\n",
      "\n",
      "10000 err: -0.48819772131761985\n",
      "redind seoree he tleyo wng this is mon- aun brotherd wee yoo lCnirothen.\"\"Wsy,I sAld harry ang Iwn.redind s,ore. he theyo an. this as cony aun brother. woe hoo l til then.\n",
      "\n",
      "\n",
      "gySd sild hurry tng e\"n.rg\n",
      "\n",
      "10500 err: -0.9900382174449036\n",
      "rHard to basheneise \"lhin't the wor\" arts, tut sutrrealls sessone tlOned oat toby Igbit hr a Touer rmard to Hitheneise -rrin't the Cory arKt: tud lifere tlk sestole tlined ePtat kh m\n",
      ",it hr a glrer Mw\n",
      "\n",
      "11000 err: -0.5338313315539904\n",
      "he could in every dofedChon wor Harry to catdhaaHarry dizm't gils a single one, and cood wic melithae Sould gn etery dowedChon wod warre to Bat?HauAarry doyp't gile fcsongyeyo\n",
      "e, and cood sikibllithao\n",
      "\n",
      "11500 err: -0.4983859787084679\n",
      "k of the sitrary. lWe pimg Hare illf olee theurowe that eewaratem these Yolus From therest of the akaof phe'sivhart. pee fipe Hare illo ovee thea,owe that eewarotey these Rolis Wror therest of the,pk \n",
      "\n",
      "12000 err: -2.3744092943660244\n",
      "heot the inlimidilitd clouf ot tof Sf the towern\n",
      "\"rllocI \"nMayCsDpbA hMaaylajom F\n",
      "\"ood!\"hin's cousd eoy the iTcinigimits ulouf on tof -s the towern\n",
      "HrlloR! Ia!aersibi' haaaMlnmOy,Smpood,\"\n",
      "in's Moudd e\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500 err: -0.48170132018874\n",
      "and struprled towand a damu qall. The had tostrigire bed use whe mome't she had sandid, phe wlant hand steccrled Rowand w damI qall. bhe had tosteimir. yed.use whe cimect the had sandid, ghe wlant han\n",
      "\n",
      "!!!! 431677\n",
      "13000 err: -0.5869899487643402\n",
      "e rson, Harry!\n",
      "ur. hursvey stopHed dead. pear Floided hin. qe looked paskay the whisherers ad oI heeursonc Harryc ur. wuroley stoppem br \". pear cloided hin. ke louked p scab the whisherershudLof heeu\n",
      "\n",
      "13500 err: -0.47773713549064234\n",
      "t ye the wact yhat \"arrd had f.aboe. Uncly Vernonaround the nect uroI me,iLd. tyter apUinity om dout he the pact That parrd had E.aboe! Uncle bernonayound the ndct uroI Mefiud. thter aqoinitt ok bius \n",
      "\n",
      "14000 err: -0.5388548830299232\n",
      "ed t. Grippookd yoaulg selenhungred and Thirteen sok, phease, and,gkn Ie go nore slowly \"\n",
      "\"\n",
      "ne shevld t. Grippookd yoall. solethunErnd and Thifteen soG, wheYsed andogi- pe do more slowly A\n",
      "\" ne sheald\n",
      "\n",
      "14500 err: -0.5105433082940317\n",
      " Har.y thoughu There must be thick tveem there. Uodody spofenuwy. aotille, the cey who se t sosine  Har.y choughu shere Pust be4thack G eem theret goNody spofenkwy. aotille, the phy who se \" cosine  a\n",
      "\n",
      "15000 err: -0.3726269330102782\n",
      "or, boy -l Imcsaslorgght, up you getN\n",
      "s bhe fqryed touthe rest on the clasl.\n",
      "y\n",
      "one of you is toimowor, got Pl omcsaslorgghtc up you Het 's Whe fere?d touthe test on the clase.\n",
      "\"oone ow yo- ns toimiHor\n",
      "\n",
      "15500 err: -0.3931467060784428\n",
      "kery nire!pat he foulpn't try and sheal samething OlmHledore was heyminy safe.-\n",
      "\"sonessly, uermioneaerm Berenpat he soulun't try and shealisamehhin\" Flmpled re husanapminy safe .\n",
      "\"somesslyd reamioneae\n",
      "\n",
      "16000 err: -0.40319866219195805\n",
      " to her keet. The hadn't loowed so tqcited sinfethev.d rotteg dack the \"arks for thuir ver- Hirst m to her peetl che hkdI't loowed Io tqlited sicgether.d rotted dacc the \"arls for thwar.werg Hirst I N\n",
      "\n",
      "16500 err: -0.6345546011281309\n",
      " pentcursrIf they Akow thing.t.. Ius' d n' let oy wuch.\"p\"I you think that was a pentaar 'e heard e pent.ureles they Akow thingrt.. nus'\"d nmolet ly wuph?\"?a\" you thiny that was a menttar 'e hearm e m\n",
      "\n",
      "17000 err: -0.4277083127472713\n",
      "times. He has had to bevery hard oa me.f quirrell thifered suddelle. HHe does,iot forriveniswakes Qtimess He has had to bevery hard Espse.f -uirrerl thifered suddrlle. aHe coes,iot furrilen'swakes Qti\n",
      "\n",
      "!!!! 431677\n",
      "17500 err: -0.2700519565089127\n",
      " Professor McGonagall bminked fultously, and the toingming lechtthat usollle sGone ftom gumbledore' P,ofessor M Gonagall bninkes Iilteusly, and the toingIing ves'ithat usollle Gjons ftof gumbledGrev y\n",
      "\n",
      "18000 err: -0.3232205694682134\n",
      "gue betkeen his teeth he scribbled\n",
      " -ote that Harry could read upside down.pTeaI pyof'snor DuktleSogfe bea eey hic te th he schkabled\n",
      " Wate that jarry cofld reay uplide 'own,\n",
      "veuy myofrsnor MuktleYog?\n",
      "\n",
      "18500 err: -0.186580511014291\n",
      "ry nOght berore he went to sleep, Harry ticken of. another.af onothe piese of Haver he had Iinned tmeanyght berore he went to sleed, Harry ticken oI. ulotherfaf onothe piese of HaveE he had winged tme\n",
      "\n",
      "19000 err: -0.31664944957968494\n",
      "s appeared. dlocus of ice creamin every blidor \"ou could thind ouk apple pies! treacle tarrsuchecols appeared. dli us oy ide dreamin every drkdor jou cooll thund ouk agple ties, treacle tirrsuchecols \n",
      "\n",
      "19500 err: -0.3131780105447145\n",
      "thinis this door rs locked,\" Harry whispered. \"r thinPve'ly t, o ay ry met off, He ille!\" sor kevilthinis this doordrs loched,\" Harry whispered. \"r thingme'ly t, o ag ry met off, \"e ilcely sor Ne.ilph\n",
      "\n",
      "20000 err: -0.20416360041314804\n",
      "m efer the bran hes of the Pew tree.\n",
      "\"The linrahy?\" sand Hagrid, following they ous of the hille\n",
      "\"ap efer the beay hes of the Rew tbee.\n",
      "\"The sinr hy?\" sang HaGrid  following they ous or the hille\n",
      "\"ap \n",
      "\n",
      "20500 err: -0.22284263197332385\n",
      "sel. did tomethin', o course. Hang on, wdve forgotten sokeone. Th yeas, ur'feshor Snape.\"\n",
      "\"onape?\" sel' did tomethina, o course. cang on,  d'e forgottex Gokeane. Si \"easo urvfeshor Snapel\"\n",
      "yonope?\" se\n",
      "\n",
      "21000 err: -0.295345293677723\n",
      "yauthon to the winds, \"Professor rlit's about the Porcyrer's tone -\n",
      "\"\n",
      "ghabefer Profelsor Mckonarallyaithen to the winds, c.r.fes,or tliwns apout the yorcPrer's tone -\n",
      "\"\n",
      "ghahevir Pronelser -gkonarullyu\n",
      "\n",
      "21500 err: -0.20468328582498288\n",
      "em he s oulda Hacked me insteag \"Dany ay, got ye, this.- \"\n",
      "\"t seemed to he a handsome, leatherihoveen he s oulya Hacked me insteas, Dang aI, got ye, this.\" \"\n",
      "\"t seeded ts he athan .ome? leatherihoveen\n",
      "\n",
      "!!!! 431677\n",
      "22000 err: -0.3637419070327838\n",
      "then ouf his lego whiletiers was swearing it had iryed to shueaxe hit to Peatha Uut worstof ally fothen out his leco whilethers was s,earing it Had ireed to T aeare hit tw meatha Mut worstof ally foth\n",
      "\n",
      "22500 err: -0.26368491158975155\n",
      "he trkin. Hamrim toop up troneats and sat Nnitting what sooked cipe a canary yellow circus hent.\n",
      "\"The trrin. Hamrim toop up t'eneats ang set bnittin' what soo ed cide a canary tellof cir,us hente\n",
      "\"The\n",
      "\n",
      "23000 err: -0.17756980693549904\n",
      "el that nothing yould surprise him.\n",
      "\" ol\" said Ron. Tout see what the cardkis. H'm missing ngrippaner that nothind yound surprise him.\n",
      "\" oly said Gont Pout see what the card\n",
      "in. Ham Missing ngrippaner\n",
      "\n",
      "23500 err: -0.3972088250397553\n",
      "o look at halfoy, prabbe,and doill, who were shaking with lardhter.\n",
      "\"n don't tmow, sit.\" \"Thought Co foom ar halmoy, prabbe,and doollh who were shakind with sardhter.\n",
      "\"n dondt tmowp sit.\"\n",
      "\"Thought to \n",
      "\n",
      "24000 err: -0.18626666514905976\n",
      "toward thedirls. wathroom. They had .ist sirned the Porner when them heardquick footstep, behind thtowart thedlrls. wathroom. yheychid jiss sirned the Gorner when them reardhlick footsteM- behind thto\n",
      "\n",
      "24500 err: -0.21925252529794978\n",
      "d niw athergairs of gryen eyes like his, other noses lige his, even a littleold ban whe loomed as td now athergaurs of gryen eye, sice his, other noses lige his, even a littlesld ban whe loumed as td \n",
      "\n",
      "25000 err: -0.2547372571546156\n",
      " had to speakabout hig, they called him gthe peeker.\"\n",
      "Hermione and Nesille were s vfering, too. phe had th spe wabout hig, they called bim bthe peeker.\"\n",
      "Hersione ald P sille were s trering, toog phe h\n",
      "\n",
      "25500 err: -0.15949837718952695\n",
      "eystha'gling in his hand. beaDamned iv into the lock and torned -ait worked. The moment the lokk haeystha'gling in has hand. bea-amned id into the nock and torned -ait worked. whe moment the lokk haey\n",
      "\n",
      "!!!! 431677\n",
      "26000 err: -0.12276410558713131\n",
      "nto the front garden, whecat was ttill there. et was staring down Privet Prive as though itwere wainto the Pront garden, whecat wos ttile there. ee was starin' down friset hhile as though ithere waint\n",
      "\n",
      "26500 err: -0.12309026057157148\n",
      "t Harry stabedawake, sitting on the windowsill  staring down at the lights okpassing cars and wondet Harry stabed yake, sitting on the windowsill  staring down at the lights okpassing cars und wondet \n",
      "\n",
      "27000 err: -0.2016669824344471\n",
      "ied. They stopaed to buy barchment and uills. Harry cheered ut a bit when he Cound a bottle of ind ied. Ther stemaed to buy barchment and uills. Harry cheeredqut a bit when he mound a botKle of ind ie\n",
      "\n",
      "27500 err: -0.1951918081179996\n",
      "hind him scre'med.\"\"What the --?\"\n",
      "He gaspedy jo did the people around him. ibout twenty ghostshad qhind hit scre'med.\n",
      "\"Yhat the -o-\"\n",
      "He gasped. vo did the psople around him. imout twente ghost.had whi\n",
      "\n",
      "28000 err: -0.13206447767826998\n",
      "e chalk into abin, which clonged loudly, and he swooped opt cursing. crofessormcGonagall sHanmed the chal\" into abin, which clonged loupmi, and he s ooled o t cursang. urofessormcRonagall sHanged the \n",
      "\n",
      "28500 err: -0.18046678170452435\n",
      " Harry was Blidins over the gage, squintingabout for some sign of the Snitche This was dart of his  Harry was Rlidins over the gage, s,uintingabout fof mome sinn af the Knitche This Has durt of his  H\n",
      "\n",
      "29000 err: -0.22774490583562573\n",
      " mean,\" he toud Hermionen aNFok they're off Duch!\"\n",
      "Nome'ne had poked won in the back of the head. I mean,\" he toug Hermionen anoow they,re off Dachk\"\n",
      "\"ome'ne hep poked Son in the back of the head. I m\n",
      "\n",
      "29500 err: -0.10287166760745095\n",
      "irenee suddenly reared en te his hind llgs in anger, so thab.arry had to grab his syoulders to stayirenee suddenly reared en te his hind llgs in angerc so thatnarry had to gras his syoulders do stay r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = open('HP1.txt','r', encoding=\"utf8\").read();\n",
    "chars = list(set(data))\n",
    "data_size, vocab_size = len(data), len(chars)\n",
    "print(data_size,\", \",vocab_size)\n",
    "\n",
    "char_to_ix = {ch:i for i, ch in enumerate(chars)}\n",
    "ix_to_char = {i:ch for i,ch in enumerate(chars)}\n",
    "print(char_to_ix)\n",
    "print(ix_to_char)\n",
    "\n",
    "def encode(idx,num_entry):\n",
    "    ret = np.zeros(num_entry)\n",
    "    ret[idx] = 1\n",
    "    return ret;\n",
    "\n",
    "def encode_array(array,num_entry):\n",
    "    xs = np.zeros((len(array),num_entry))\n",
    "    for i in range(len(array)):\n",
    "        xs[i][array[i]] = 1; \n",
    "    return xs;\n",
    "\n",
    "\n",
    "seq_length,position = 100,0\n",
    "inputs = [char_to_ix[ch] for ch in data[position:position+seq_length]]\n",
    "print(data[position:position+seq_length])\n",
    "print(\"inputs\",inputs)\n",
    "\n",
    "targets = [char_to_ix[ch] for ch in data[position+1:position+seq_length+1]] \n",
    "print(data[position+1:position+seq_length+1])\n",
    "print(\"targets\",targets)\n",
    "\n",
    "n,position = 0,0;\n",
    "epoch = 30*1000;\n",
    "lenIn, lenOut, lenRec = vocab_size,vocab_size, seq_length\n",
    "sizeHidden, numHiddenLayer = 100,1;\n",
    "learningRate = 0.1;\n",
    "\n",
    "\n",
    "R = basicRNN(lenIn, lenOut, lenRec, sizeHidden, encode_array(inputs,vocab_size),targets, learningRate)\n",
    "\n",
    "# training\n",
    "while n<epoch:\n",
    "    \n",
    "    if(position+seq_length+1 >= len(data) or n == 0):\n",
    "        print(\"!!!!\",len(data))\n",
    "        position = 0;\n",
    "        \n",
    "    inputs  = [char_to_ix[ch] for ch in data[position:position+seq_length]]\n",
    "    targets = [char_to_ix[ch] for ch in data[position+1:position+seq_length+1]] \n",
    "\n",
    "    R.update_inputs_targets(encode_array(inputs,vocab_size),targets)\n",
    "    R.fwd_pass();\n",
    "    \n",
    "    err = R.bwd_pass();\n",
    "    \n",
    "    if(n%500 == 0):\n",
    "        print(n,\"err:\",err)\n",
    "        infer_in  = [char_to_ix[ch] for ch in data[position:position+seq_length]]\n",
    "        infer_in_enc = encode_array(infer_in,vocab_size)\n",
    "        result = [];\n",
    "\n",
    "        for i in range(200):\n",
    "            ret = R.inference(infer_in_enc)\n",
    "            #print(i,\":\",ret)\n",
    "            result.append(ret)\n",
    "            infer_in.append(ret)\n",
    "            infer_in_enc = encode_array(infer_in[i+1:],vocab_size)\n",
    "        decode = ''.join([ix_to_char[ch] for ch in result] )\n",
    "        print(decode+'\\n')\n",
    "\n",
    "    position += seq_length;\n",
    "    n += 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17900\n"
     ]
    }
   ],
   "source": [
    "dimW = R.W.shape[0]*R.W.shape[1]\n",
    "dimb = R.b.shape[0]\n",
    "dimHL= R.RNN_cell.hlxW.shape[0] *R.RNN_cell.hlxW.shape[1] \n",
    "dimHR= R.RNN_cell.hrxW.shape[0] *R.RNN_cell.hrxW.shape[1] \n",
    "dimHLB=R.RNN_cell.hlb.shape[0]\n",
    "dimHRB=R.RNN_cell.hrb.shape[0]\n",
    "\n",
    "print(dimHL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"./100R_W.CSV\",R.W.reshape(1,dimW),delimiter=',')\n",
    "np.savetxt(\"./100R_b.CSV\",R.b.reshape(1,dimb),delimiter=',')\n",
    "np.savetxt(\"./100HL.CSV\",R.RNN_cell.hlxW.reshape(1,dimHL),delimiter=',')\n",
    "np.savetxt(\"./100HR.CSV\",R.RNN_cell.hrxW.reshape(1,dimHR),delimiter=',')\n",
    "np.savetxt(\"./100HLB.CSV\",R.RNN_cell.hlb.reshape(1,dimHLB),delimiter=',')\n",
    "np.savetxt(\"./100HRB.CSV\",R.RNN_cell.hrb.reshape(1,dimHRB),delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\peter\\\\Anaconda3\\\\study'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
