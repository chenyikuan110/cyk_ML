{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "431677 ,  79\n",
      "{'E': 0, 'Y': 1, 'o': 2, 'K': 3, '6': 4, 'Q': 5, 'v': 6, 'N': 7, 'c': 8, '7': 9, 'u': 10, 'm': 11, '.': 12, '9': 13, '(': 14, '\\\\': 15, 'b': 16, 'n': 17, 't': 18, 'W': 19, 'q': 20, 'l': 21, '\\n': 22, '2': 23, '\"': 24, 'V': 25, '~': 26, 'y': 27, 'f': 28, 'A': 29, 'L': 30, 'p': 31, 'R': 32, '!': 33, 'x': 34, 'B': 35, '1': 36, 'r': 37, 'H': 38, 'j': 39, '3': 40, '*': 41, ' ': 42, 'e': 43, 'I': 44, 'G': 45, 'P': 46, ',': 47, ';': 48, 'U': 49, 'w': 50, ':': 51, 'C': 52, ')': 53, 'S': 54, 'd': 55, 'g': 56, 'J': 57, '4': 58, 's': 59, '5': 60, '?': 61, '\\t': 62, \"'\": 63, 'X': 64, 'Z': 65, 'T': 66, 'i': 67, 'F': 68, 'M': 69, '-': 70, 'h': 71, 'D': 72, 'a': 73, '0': 74, 'z': 75, 'O': 76, '8': 77, 'k': 78}\n",
      "{0: 'E', 1: 'Y', 2: 'o', 3: 'K', 4: '6', 5: 'Q', 6: 'v', 7: 'N', 8: 'c', 9: '7', 10: 'u', 11: 'm', 12: '.', 13: '9', 14: '(', 15: '\\\\', 16: 'b', 17: 'n', 18: 't', 19: 'W', 20: 'q', 21: 'l', 22: '\\n', 23: '2', 24: '\"', 25: 'V', 26: '~', 27: 'y', 28: 'f', 29: 'A', 30: 'L', 31: 'p', 32: 'R', 33: '!', 34: 'x', 35: 'B', 36: '1', 37: 'r', 38: 'H', 39: 'j', 40: '3', 41: '*', 42: ' ', 43: 'e', 44: 'I', 45: 'G', 46: 'P', 47: ',', 48: ';', 49: 'U', 50: 'w', 51: ':', 52: 'C', 53: ')', 54: 'S', 55: 'd', 56: 'g', 57: 'J', 58: '4', 59: 's', 60: '5', 61: '?', 62: '\\t', 63: \"'\", 64: 'X', 65: 'Z', 66: 'T', 67: 'i', 68: 'F', 69: 'M', 70: '-', 71: 'h', 72: 'D', 73: 'a', 74: '0', 75: 'z', 76: 'O', 77: '8', 78: 'k'}\n"
     ]
    }
   ],
   "source": [
    "data = open('HP1.txt','r', encoding=\"utf8\").read();\n",
    "chars = list(set(data))\n",
    "data_size, vocab_size = len(data), len(chars)\n",
    "print(data_size,\", \",vocab_size)\n",
    "\n",
    "char_to_ix = {ch:i for i, ch in enumerate(chars)}\n",
    "ix_to_char = {i:ch for i,ch in enumerate(chars)}\n",
    "print(char_to_ix)\n",
    "print(ix_to_char)\n",
    "\n",
    "def encode(idx,num_entry):\n",
    "    ret = np.zeros(num_entry)\n",
    "    ret[idx] = 1\n",
    "    return ret;\n",
    "\n",
    "def encode_array(array,num_entry):\n",
    "    xs = np.zeros((len(array),num_entry))\n",
    "    for i in range(len(array)):\n",
    "        xs[i][array[i]] = 1; \n",
    "    return xs;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "# Helper functions\n",
    "def softmax(array):\n",
    "    return np.exp(array)/ np.sum(np.exp(array)) # return an array\n",
    "\n",
    "def sigmoid(x):\n",
    "    return (1/(1+np.exp(-x)))\n",
    "\n",
    "def sigmoid_deriv(y):\n",
    "    return (y*(1-y))\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def tanh_deriv(y):\n",
    "    return 1 - pow(np.tanh(y),2)\n",
    "\n",
    "# RNN\n",
    "class myRNN:\n",
    "    \n",
    "    def __init__ (self, lenIn, lenOut, lenRec, sizeHidden, inputs_encoded, targets, learningRate,dropout_threshold):\n",
    "        \n",
    "        # Hyper parameters\n",
    "        self.lenIn          = lenIn\n",
    "        self.lenOut         = lenOut\n",
    "        self.lenRec         = lenRec\n",
    "        self.sizeHidden     = sizeHidden\n",
    "        self.learningRate   = learningRate\n",
    "        self.dropout_threshold = dropout_threshold\n",
    "        \n",
    "        # input & expected output\n",
    "        self.inputs_encoded = inputs_encoded;\n",
    "        self.targets = targets;\n",
    "        \n",
    "        # parameters for inference\n",
    "        self.x  = np.zeros(lenIn)  \n",
    "        self.y  = np.zeros(lenOut)\n",
    "        self.h  = np.zeros(sizeHidden)\n",
    "        self.c  = np.zeros(sizeHidden)\n",
    "        \n",
    "        self.W  = np.zeros((lenOut,sizeHidden)) # for the last fully connected layer\n",
    "        self.GW = np.zeros((lenOut,sizeHidden)) # Gradient, for W-update using RMSprop\n",
    "        self.b  = np.zeros(lenOut)\n",
    "        self.Gb = np.zeros(lenOut)\n",
    "        \n",
    "        # for training phase \n",
    "        self.xs = np.zeros((lenRec,lenIn))\n",
    "        self.ys = np.zeros((lenRec,lenOut))\n",
    "        self.cs = np.zeros((lenRec,sizeHidden))\n",
    "        self.hs = np.zeros((lenRec,sizeHidden))\n",
    "        \n",
    "        # for training phase bookkeeping\n",
    "        self.fg = np.zeros((lenRec,sizeHidden)) # forget gate\n",
    "        self.ig = np.zeros((lenRec,sizeHidden)) # input  gate\n",
    "        self.og = np.zeros((lenRec,sizeHidden)) # output gate\n",
    "        self.mc = np.zeros((lenRec,sizeHidden)) # memory cell state (candidate)\n",
    "        \n",
    "        # LSTM class\n",
    "        self.LSTM = LSTM(sizeHidden+lenIn,sizeHidden,lenRec,learningRate)\n",
    "        \n",
    "        # Dropout vector\n",
    "        self.dvo = np.zeros((lenRec,sizeHidden));\n",
    "        \n",
    "        ''' end of myRNN.__init__ '''\n",
    "       \n",
    "    ''' This is used when mini-batch is used '''            \n",
    "    def update_inputs_targets(self, inputs_encoded, targets):\n",
    "        self.inputs_encoded  = inputs_encoded\n",
    "        self.targets         = targets\n",
    "    \n",
    "    def fwd_pass(self): \n",
    "                \n",
    "        prev_h = np.zeros_like(self.hs[0])\n",
    "        for t in range(0,self.lenRec):\n",
    "            for i in range(self.dvo.shape[1]):\n",
    "                rand = np.random.random()\n",
    "                if(rand > self.dropout_threshold):\n",
    "                    self.dvo[t][i] = 1;\n",
    "                else:\n",
    "                    self.dvo[t][i] = 0;\n",
    "            # update input\n",
    "            self.x    = self.inputs_encoded[t]\n",
    "            self.xs[t]= self.inputs_encoded[t]\n",
    "            \n",
    "            self.LSTM.hx = np.hstack((prev_h, self.x));\n",
    "            self.LSTM.dvo = self.dvo[t];\n",
    "            \n",
    "            c, h, f, i, m, o = self.LSTM.fwd_pass()\n",
    "            # bookkeeping\n",
    "            self.cs[t] = c\n",
    "            self.hs[t] = h\n",
    "            self.fg[t] = f\n",
    "            self.ig[t] = i\n",
    "            self.mc[t] = m\n",
    "            self.og[t] = o\n",
    "            \n",
    "            # output layer - fully connected layer\n",
    "            self.ys[t] = np.dot(self.W,self.hs[t]) + self.b\n",
    "            prev_h = self.hs[t]\n",
    "            \n",
    "        return;              \n",
    "    \n",
    "    def bwd_pass(self):        \n",
    "\n",
    "        avg_loss = 0; # using cross entropy average\n",
    "        c2next_grad  = np.zeros(self.sizeHidden)\n",
    "        h2next_grad  = np.zeros(self.sizeHidden)\n",
    "        \n",
    "        # output bp\n",
    "        W_grad   = np.zeros((self.lenOut,self.sizeHidden))\n",
    "        b_grad  = np.zeros(self.lenOut)\n",
    "        \n",
    "        # LSTM internal bp\n",
    "        hxf_grad   = np.zeros((self.sizeHidden,self.LSTM.lenIn));\n",
    "        hxi_grad   = np.zeros((self.sizeHidden,self.LSTM.lenIn));\n",
    "        hxm_grad   = np.zeros((self.sizeHidden,self.LSTM.lenIn));\n",
    "        hxo_grad   = np.zeros((self.sizeHidden,self.LSTM.lenIn));\n",
    "    \n",
    "        fb_grad   = np.zeros(self.sizeHidden)\n",
    "        ib_grad   = np.zeros(self.sizeHidden)\n",
    "        mb_grad   = np.zeros(self.sizeHidden)\n",
    "        ob_grad   = np.zeros(self.sizeHidden)\n",
    "                   \n",
    "        # propagates through time and layers\n",
    "\n",
    "        for t in reversed(range(0,self.lenRec)):\n",
    "            \n",
    "            prob = softmax(self.ys[t]) # prevent zero\n",
    "            prob_fix  = prob + 1e-9\n",
    "#            if(prob[self.targets[t]] == 0):\n",
    "#                for ii in range(10000):\n",
    "#                    print(\"ERR!\",self.ys[t][self.targets[t]],\" \",np.sum(self.ys[t]))\n",
    "                \n",
    "            # cross entropy\n",
    "            err       = np.log(prob_fix[int(self.targets[t])])\n",
    "            avg_loss += err\n",
    "     \n",
    "            dy = copy.deepcopy(prob)\n",
    "            dy[int(self.targets[t])] -= 1\n",
    "            \n",
    "            W_grad += np.dot((np.atleast_2d(dy)).T,np.atleast_2d(self.hs[t]))\n",
    "            b_grad += dy\n",
    "            \n",
    "            dh = np.dot(self.W.T,dy) + h2next_grad\n",
    "            \n",
    "            x_grad  = np.zeros(self.lenIn)\n",
    "            \n",
    "            if(t > 0):\n",
    "                prev_h = self.hs[t-1]\n",
    "                prev_c = self.cs[t-1]\n",
    "            else:\n",
    "                prev_h = np.zeros_like(self.hs[0])\n",
    "                prev_c = np.zeros_like(self.cs[0])\n",
    "                \n",
    "            self.LSTM.hx = np.hstack((prev_h,self.xs[t]));\n",
    "            self.LSTM.c = self.cs[t];\n",
    "            \n",
    "            self.LSTM.dvo = self.dvo[t];\n",
    "            \n",
    "            dhxf,dhxi,dhxm,dhxo, dbf,dbi,dbm,dbo, c2next_grad,h2next_grad,x_grad = \\\n",
    "            self.LSTM.bwd_pass( dh, prev_c ,self.fg[t],self.ig[t],self.mc[t],self.og[t],\\\n",
    "                                 c2next_grad);\n",
    "            \n",
    "            for ii in range(dhxo.shape[0]):\n",
    "                dhxo[ii] *= self.dvo[t][ii];   \n",
    "                \n",
    "            hxf_grad +=  dhxf;\n",
    "            hxi_grad +=  dhxi;  \n",
    "            hxm_grad +=  dhxm;  \n",
    "            hxo_grad +=  dhxo;   \n",
    "            \n",
    "            fb_grad +=  dbf;\n",
    "            ib_grad +=  dbi;\n",
    "            mb_grad +=  dbm;\n",
    "            ob_grad +=  np.multiply(dbo,self.dvo[t]);   \n",
    "\n",
    "        \n",
    "        # update using RMSprop\n",
    "        self.LSTM.update(hxf_grad/self.lenRec, hxi_grad/self.lenRec, \\\n",
    "                           hxm_grad/self.lenRec, hxo_grad/self.lenRec, \\\n",
    "                           fb_grad/self.lenRec, ib_grad/self.lenRec, \\\n",
    "                           mb_grad/self.lenRec, ob_grad/self.lenRec);\n",
    "\n",
    "        \n",
    "        self.update(W_grad/self.lenRec,b_grad/self.lenRec);\n",
    "        return avg_loss/self.lenRec;\n",
    "            \n",
    "          \n",
    "            \n",
    "    def update(self, W_grad, b_grad):\n",
    "        self.GW = 0.9*self.GW + 0.1*W_grad**2;\n",
    "        self.W -= self.learningRate/np.sqrt(self.GW + 1e-8) * W_grad;\n",
    "        self.Gb = 0.9*self.Gb + 0.1*b_grad**2;\n",
    "        self.b -= self.learningRate/np.sqrt(self.Gb + 1e-8) * b_grad;\n",
    "\n",
    "    def inference(self,x):\n",
    "        # update input\n",
    "        self.x = x\n",
    "        self.LSTM.hx = np.hstack((self.h,self.x))\n",
    "        c, h, f, i, m, o = self.LSTM.fwd_pass()\n",
    "        self.c = c\n",
    "        self.h = h\n",
    "\n",
    "        # output layer - may replace with softmax instead\n",
    "        self.y = np.dot(self.W,self.h) + self.b\n",
    "        p   = softmax(self.y)     \n",
    "        return np.random.choice(range(self.lenOut), p=p.ravel())\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LSTM:\n",
    "    \n",
    "    def __init__ (self,lenIn,sizeHidden,lenRec,learningRate):\n",
    "        self.lenIn        = lenIn\n",
    "        self.sizeHidden   = sizeHidden\n",
    "        self.lenRec       = lenRec\n",
    "        self.learningRate = learningRate\n",
    "        \n",
    "        # hx == x is x and h horizontally stacked together\n",
    "        self.hx = np.zeros(lenIn)\n",
    "        self.c = np.zeros(sizeHidden)\n",
    "        self.h = np.zeros(sizeHidden)\n",
    "        \n",
    "        # Weight matrices\n",
    "        self.fW = np.random.random((sizeHidden,lenIn));\n",
    "        self.iW = np.random.random((sizeHidden,lenIn));\n",
    "        self.mW = np.random.random((sizeHidden,lenIn)); # cell state\n",
    "        self.oW = np.random.random((sizeHidden,lenIn));\n",
    "                             \n",
    "        # biases\n",
    "        self.fb = np.zeros(sizeHidden);\n",
    "        self.ib = np.zeros(sizeHidden); \n",
    "        self.mb = np.zeros(sizeHidden); \n",
    "        self.ob = np.zeros(sizeHidden); \n",
    "               \n",
    "        # for RMSprop only\n",
    "        self.GfW = np.random.random((sizeHidden,lenIn));\n",
    "        self.GiW = np.random.random((sizeHidden,lenIn));\n",
    "        self.GmW = np.random.random((sizeHidden,lenIn)); \n",
    "        self.GoW = np.random.random((sizeHidden,lenIn));\n",
    "                             \n",
    "        self.Gfb = np.zeros(sizeHidden);\n",
    "        self.Gib = np.zeros(sizeHidden); \n",
    "        self.Gmb = np.zeros(sizeHidden);\n",
    "        self.Gob = np.zeros(sizeHidden); \n",
    "        \n",
    "        # for dropout\n",
    "        self.dvo = np.zeros(sizeHidden); \n",
    "        ''' end of LSTM.__init__ '''\n",
    "        \n",
    "    def fwd_pass(self):\n",
    "        f       = sigmoid(np.dot(self.fW, self.hx) + self.fb)\n",
    "        i       = sigmoid(np.dot(self.iW, self.hx) + self.ib)\n",
    "        m       = tanh(   np.dot(self.mW, self.hx) + self.mb)        \n",
    "        o       = sigmoid(np.dot(self.oW, self.hx) + self.ob)\n",
    "        o       = np.multiply(o,self.dvo); # dropout\n",
    "        self.c *= f\n",
    "        self.c += i * m\n",
    "        self.h  = o * tanh(self.c)\n",
    "        \n",
    "        return self.c, self.h, f, i, m, o;\n",
    "    \n",
    "    def bwd_pass(self, dh, prev_c, f, i, m, o, c_g):\n",
    "        \n",
    "        dh = np.clip(dh, -6, 6);       \n",
    "        # h = o*tanh(c)\n",
    "        do  = tanh(self.c) * dh\n",
    "        do  = sigmoid_deriv(o)*do\n",
    "        #do  = np.multiply(do,self.dvo)\n",
    "        dhxo = np.dot((np.atleast_2d(do)).T,np.atleast_2d(self.hx)) \n",
    "        \n",
    "        # h = o*tanh(c) - add c_g (c_grad in next timestep, account for the branch here)\n",
    "        dcs = dh * o * tanh_deriv(self.c) + c_g\n",
    "        dcs = np.clip(dcs, -6, 6); \n",
    "        \n",
    "        # c = c_prev * f + m * i\n",
    "        dm = i * dcs\n",
    "        dm = tanh_deriv(m) * dm\n",
    "        dhxm = np.dot((np.atleast_2d(dm)).T,np.atleast_2d(self.hx)) \n",
    "        \n",
    "        # c = c_prev * f + m * i\n",
    "        di  = m * dcs\n",
    "        di  = sigmoid_deriv(i) * di\n",
    "        dhxi = np.dot((np.atleast_2d(di)).T,np.atleast_2d(self.hx)) \n",
    "        \n",
    "        # c = c_prev * f + m * i\n",
    "        df = prev_c * dcs\n",
    "        df = sigmoid_deriv(f) * df\n",
    "        dhxf = np.dot((np.atleast_2d(df)).T,np.atleast_2d(self.hx)) \n",
    "        \n",
    "        # c = c_prev * f + m * i\n",
    "        c_grad  = dcs * f\n",
    "        hx_grad = np.dot(self.fW.T, df) + np.dot(self.iW.T, di) +\\\n",
    "                          np.dot(self.oW.T, do) + np.dot(self.mW.T, dm)\n",
    "        \n",
    "        \n",
    "        return dhxf,dhxi,dhxm,dhxo,df,di,dm,do,c_grad,hx_grad[:self.sizeHidden],hx_grad[self.sizeHidden:];\n",
    "    \n",
    "    def update(self, f_grad, i_grad, m_grad, o_grad, fb_grad, ib_grad, mb_grad, ob_grad):\n",
    "\n",
    "        self.GfW = 0.9*self.GfW + 0.1*f_grad**2\n",
    "        self.GiW = 0.9*self.GiW + 0.1*i_grad**2\n",
    "        self.GmW = 0.9*self.GmW + 0.1*m_grad**2\n",
    "        self.GoW = 0.9*self.GoW + 0.1*o_grad**2\n",
    "        \n",
    "        self.Gfb = 0.9*self.Gfb + 0.1*fb_grad**2\n",
    "        self.Gib = 0.9*self.Gib + 0.1*ib_grad**2\n",
    "        self.Gmb = 0.9*self.Gmb + 0.1*mb_grad**2\n",
    "        self.Gob = 0.9*self.Gob + 0.1*ob_grad**2\n",
    "        \n",
    "        self.fW -= self.learningRate/np.sqrt(self.GfW + 1e-8) * f_grad\n",
    "        self.iW -= self.learningRate/np.sqrt(self.GiW + 1e-8) * i_grad\n",
    "        self.mW -= self.learningRate/np.sqrt(self.GmW + 1e-8) * m_grad\n",
    "        self.oW -= self.learningRate/np.sqrt(self.GoW + 1e-8) * o_grad\n",
    "        \n",
    "        self.fb -= self.learningRate/np.sqrt(self.Gfb + 1e-8) * fb_grad\n",
    "        self.ib -= self.learningRate/np.sqrt(self.Gib + 1e-8) * ib_grad\n",
    "        self.mb -= self.learningRate/np.sqrt(self.Gmb + 1e-8) * mb_grad\n",
    "        self.ob -= self.learningRate/np.sqrt(self.Gob + 1e-8) * ob_grad\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harry Potter and the Sorcerer's Stone\n",
      "CHAPTER ONE\n",
      "THE BOY WHO LIVED\n",
      "Mr. and\n",
      "inputs [38, 73, 37, 37, 27, 42, 46, 2, 18, 18, 43, 37, 42, 73, 17, 55, 42, 18, 71, 43, 42, 54, 2, 37, 8, 43, 37, 43, 37, 63, 59, 42, 54, 18, 2, 17, 43, 22, 52, 38, 29, 46, 66, 0, 32, 42, 76, 7, 0, 22, 66, 38, 0, 42, 35, 76, 1, 42, 19, 38, 76, 42, 30, 44, 25, 0, 72, 22, 69, 37, 12, 42, 73, 17, 55]\n",
      "arry Potter and the Sorcerer's Stone\n",
      "CHAPTER ONE\n",
      "THE BOY WHO LIVED\n",
      "Mr. and \n",
      "targets [73, 37, 37, 27, 42, 46, 2, 18, 18, 43, 37, 42, 73, 17, 55, 42, 18, 71, 43, 42, 54, 2, 37, 8, 43, 37, 43, 37, 63, 59, 42, 54, 18, 2, 17, 43, 22, 52, 38, 29, 46, 66, 0, 32, 42, 76, 7, 0, 22, 66, 38, 0, 42, 35, 76, 1, 42, 19, 38, 76, 42, 30, 44, 25, 0, 72, 22, 69, 37, 12, 42, 73, 17, 55, 42]\n",
      "!!!! 431677\n",
      "0 err: -4.36944777346702  R.learningRate: 0.1 dropout_threshold: 0.09999999999999998\n",
      "E\n",
      "<Inference>:\n",
      "nHdSP O\n",
      "E e h oSEdOtPre\n",
      "TPPP\n",
      "HEOPdetOdtP\n",
      "\n",
      "<Predict>:\n",
      "<Predict>: oTOSo \n",
      "EdEeenoeEtPdnTHPtHPMWteoO\n",
      "\n",
      "CPTE\n",
      "n\n",
      "<Targets>: arry Potter and the Sorcerer's Stone\n",
      "CHA\n",
      "500 err: -2.2999722725743106  R.learningRate: 0.09756147122503571 dropout_threshold: 0.14389351794935734\n",
      "~\n",
      "<Inference>:\n",
      "unt this had ut a Hat leit co jHarrerore\n",
      "\n",
      "<Predict>:\n",
      "<Predict>: eodor w meeic thrd  too sudi ya  trrtht \n",
      "<Targets>: owded withfamilies. The Dursleys bought \n",
      "1000 err: -2.2144142983491784  R.learningRate: 0.09524187090179798 dropout_threshold: 0.18564632376763646\n",
      "C\n",
      "<Inference>:\n",
      "leverave.very patpe;fakightno them crast\n",
      "\n",
      "<Predict>:\n",
      "<Predict>: egf.y hnw sao itsaserl,w yhatewho shsbo-\n",
      "<Targets>:  only one who saw herfor what she was --\n",
      "1500 err: -2.218259731300471  R.learningRate: 0.09303539882125289 dropout_threshold: 0.225362821217448\n",
      "k\n",
      "<Inference>:\n",
      "sym at \"Youtfehbougpepay widotuycveiler \n",
      "\n",
      "<Predict>:\n",
      "<Predict>: hshuiupyi auony   \n",
      "\"D's totsthvlnvtnhed \n",
      "<Targets>:  to curse Dudley.\"\n",
      "\"I'm not sayin' that'\n",
      "2000 err: -1.925414886392873  R.learningRate: 0.0909365376538991 dropout_threshold: 0.26314232222981637\n",
      "V\n",
      "<Inference>:\n",
      "Oleiildstini\n",
      "ormer. grockew abrsore ha's\n",
      "\n",
      "<Predict>:\n",
      "<Predict>: -.woth,bahstey hiriu-nd\"tae b  b  y no -\n",
      "<Targets>: o with his brothers and the broomstick h\n",
      "2500 err: -2.338216099900358  R.learningRate: 0.08894003915357025 dropout_threshold: 0.2990792952357356\n",
      ":\n",
      "<Inference>:\n",
      " to a ones, bot thoumbed weatwitarrrver \n",
      "\n",
      "<Predict>:\n",
      "<Predict>: ihtn Pas tthvAr  hrfk au hsr dhw  shdk  \n",
      "<Targets>: t it was stuffed full ofgarlic as well, \n",
      "3000 err: -2.1574499895715764  R.learningRate: 0.0870409110340859 dropout_threshold: 0.33326360138645394\n",
      "8\n",
      "<Inference>:\n",
      "bedrand theom doch reidHered and sating \n",
      "\n",
      "<Predict>:\n",
      "<Predict>: tdcs ohlmorwan grsntn ath,lpenh,ts taotu\n",
      "<Targets>: nted to do was put asmuch space as possi\n",
      "3500 err: -2.329927307755737  R.learningRate: 0.08523440448593567 dropout_threshold: 0.3657807192531579\n",
      "\"\n",
      "<Inference>:\n",
      "ses,\"\n",
      "\"Whit thecesed you ge fid ssw e fe\n",
      "\n",
      "<Predict>:\n",
      "<Predict>: en ,  HFe''shedgstbet peleky, aaamd \n",
      "hon\n",
      "<Targets>: ame!\"\n",
      "\"But this isn't soccer, Dean,\" Ron\n",
      "4000 err: -2.088990150071868  R.learningRate: 0.08351600230178197 dropout_threshold: 0.3967119585679246\n",
      "w\n",
      "<Inference>:\n",
      "arkon, lothisgen beagilispibedirrer forr\n",
      "\n",
      "<Predict>:\n",
      "<Predict>: oafemryp itenht  hira snhisetwewlllwlmli\n",
      "<Targets>:  of green light,while a high voice cackl\n",
      "4500 err: -2.514473160599652  R.learningRate: 0.08188140758108867 dropout_threshold: 0.42613466354040397\n",
      "O\n",
      "<Inference>:\n",
      "w puseileilly had the counds it bouse be\n",
      "\n",
      "<Predict>:\n",
      "<Predict>: tptoe woriasttosthisloe th     oearh.tas\n",
      "<Targets>: p the tallest astronomy tower, which was\n",
      "5000 err: -1.7799530557730971  R.learningRate: 0.08032653298563168 dropout_threshold: 0.4541224062586299\n",
      "2\n",
      "<Inference>:\n",
      "ninucame's bloung thattow Harry goid, th\n",
      "\n",
      "<Predict>:\n",
      "<Predict>: lghn loindor gar,\"HPbnnwast soewehteo  a\n",
      "<Targets>:  was goingto say.\n",
      "\"You want to be more c\n",
      "5500 err: -2.4324838925819554  R.learningRate: 0.07884749051902434 dropout_threshold: 0.48074517065756195\n",
      "U\n",
      "<Inference>:\n",
      "ruavere. \"\n",
      "she,  trisuemormle fore, a ke\n",
      "\n",
      "<Predict>:\n",
      "<Predict>: ees ehorhonl ekeere WThl,  tuoiu,tou yuo\n",
      "<Targets>: halfthe candy shop.\n",
      "\"Tokens from your fr\n",
      "!!!! 431677\n",
      "6000 err: -2.787160847648234  R.learningRate: 0.07744058180470133 dropout_threshold: 0.5060695275153761\n",
      "z\n",
      "<Inference>:\n",
      "eipcp -- thing in the were... the fin na\n",
      "\n",
      "<Predict>:\n",
      "<Predict>: oo t e e anavhnd falsoe n be .wceascee.m\n",
      "<Targets>: handkerchief and dabbedat her eyes benea\n",
      "6500 err: -2.317366194096354  R.learningRate: 0.07610228883805081 dropout_threshold: 0.5301588009150855\n",
      "\n",
      "\n",
      "<Inference>:\n",
      "\"\n",
      "\"\n",
      " it the glor are. Harry, you set. o \n",
      "\n",
      "<Predict>:\n",
      "<Predict>: hhn  tuilely.ond tooe.e, hnsi ' st Ha ,t\n",
      "<Targets>:  off quickly and dressed silently. Hemus\n",
      "7000 err: -5.259024803444269  R.learningRate: 0.07482926518957048 dropout_threshold: 0.5530732265877314\n",
      ";\n",
      "<Inference>:\n",
      "\n",
      "L as saphe set hispe he apbdingsed tce \n",
      "\n",
      "<Predict>:\n",
      "<Predict>: aTf OSSnVTTaB Nz e G\n",
      "\"Toa\n",
      "JHWraCpOLOak\"Z\n",
      "<Targets>: YEARS ARE NOT ALLOWED THEIROWN BROOMSTIC\n",
      "7500 err: -2.032378608162095  R.learningRate: 0.07361832763705074 dropout_threshold: 0.5748701025330868\n",
      "0\n",
      "<Inference>:\n",
      "p. Heradn'the teris itbooh rearre blin i\n",
      "\n",
      "<Predict>:\n",
      "<Predict>: xt innirttner toe ni n  in che daet orpn\n",
      "<Targets>:  drifted over the heads of the chatterin\n",
      "8000 err: -2.285503235246374  R.learningRate: 0.07246644820586108 dropout_threshold: 0.5956039322945006\n",
      "l\n",
      "<Inference>:\n",
      "yd of thane! \"of upperslairry the!\"\n",
      "\"Gxk\n",
      "\n",
      "<Predict>:\n",
      "<Predict>: di.herids d  aee.heryng HGo ctoe,herine \n",
      "<Targets>: lytherin,not Slytherin.\n",
      "\"Not Slytherin, \n",
      "8500 err: -2.1177744451782305  R.learningRate: 0.07137074659743634 dropout_threshold: 0.6153265612461459\n",
      ",\n",
      "<Inference>:\n",
      " and oftand overs omst teallas up aroms \n",
      "\n",
      "<Predict>:\n",
      "<Predict>: aclgat rrg'ycso \n",
      "\"Moyte\"e\"ayd tadaayl eo\n",
      "<Targets>: abies, Parvati.\"\n",
      "\"Look!\" said Malfoy, da\n",
      "9000 err: -2.4876603822580776  R.learningRate: 0.07032848298702996 dropout_threshold: 0.6340873062334608\n",
      "a\n",
      "<Inference>:\n",
      "ot. Harry ugdoods und bunding trapbliony\n",
      "\n",
      "<Predict>:\n",
      "<Predict>: sin wm  \n",
      "Tt aisrhl, d ,wotghtmuo  fucand\n",
      "<Targets>:  inside. It waggledits long ears, making\n",
      "9500 err: -2.3694147540954824  R.learningRate: 0.06933705117272507 dropout_threshold: 0.6519330788909489\n",
      "q\n",
      "<Inference>:\n",
      "utler, seere's heard face the wough fo o\n",
      "\n",
      "<Predict>:\n",
      "<Predict>: feioftr  fhre\"she iuul.weng aue lkhouF a\n",
      "<Targets>: n before were the followingwords: Your f\n",
      "10000 err: -1.9288431656500276  R.learningRate: 0.06839397205857212 dropout_threshold: 0.6689085029457018\n",
      "P\n",
      "<Inference>:\n",
      "orranti, eryt thegtodleyssspeinklydyygin\n",
      "\n",
      "<Predict>:\n",
      "<Predict>: kwe td. Serryrt n songharnd sn gayerbugd\n",
      "<Targets>:  notes. Harry and Ron wouldn't have mind\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-8c2a40a2d68f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[0mR\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfwd_pass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m     \u001b[0merr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mR\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbwd_pass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m     \u001b[0merr_curve\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-36-d4e6a2a8572a>\u001b[0m in \u001b[0;36mbwd_pass\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    165\u001b[0m                 \u001b[0mdhxo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mii\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdvo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mii\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 167\u001b[1;33m             \u001b[0mhxf_grad\u001b[0m \u001b[1;33m+=\u001b[0m  \u001b[0mdhxf\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    168\u001b[0m             \u001b[0mhxi_grad\u001b[0m \u001b[1;33m+=\u001b[0m  \u001b[0mdhxi\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m             \u001b[0mhxm_grad\u001b[0m \u001b[1;33m+=\u001b[0m  \u001b[0mdhxm\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Try a reduced/increased drop out probability\n",
    "\n",
    "\n",
    "seq_length,position = 75,0\n",
    "inputs = [char_to_ix[ch] for ch in data[position:position+seq_length]]\n",
    "print(data[position:position+seq_length])\n",
    "print(\"inputs\",inputs)\n",
    "\n",
    "targets = [char_to_ix[ch] for ch in data[position+1:position+seq_length+1]] \n",
    "print(data[position+1:position+seq_length+1])\n",
    "print(\"targets\",targets)\n",
    "\n",
    "n,position = 0,0;\n",
    "epoch = 20*1000;\n",
    "lenIn, lenOut, lenRec = vocab_size,vocab_size, seq_length\n",
    "sizeHidden, numHiddenLayer = 64,1;\n",
    "learningRate = 0.1;\n",
    "dropout_threshold = 0.1;\n",
    "\n",
    "R = myRNN(lenIn, lenOut, lenRec, sizeHidden, encode_array(inputs,vocab_size),targets, learningRate,dropout_threshold)\n",
    "\n",
    "# training\n",
    "\n",
    "err_curve = [];\n",
    "\n",
    "while n<epoch:\n",
    "    R.learningRate = 0.05+0.05*np.exp(-n/(100*100))\n",
    "    R.dropout_threshold = 0.7-0.6*np.exp(-n/(100*100))\n",
    "    \n",
    "    if(position+seq_length+1 >= len(data) or n == 0):\n",
    "        print(\"!!!!\",len(data))\n",
    "        position = 0;\n",
    "        \n",
    "    inputs  = [char_to_ix[ch] for ch in data[position:position+seq_length]]\n",
    "    targets = [char_to_ix[ch] for ch in data[position+1:position+seq_length+1]] \n",
    "\n",
    "    R.update_inputs_targets(encode_array(inputs,vocab_size),targets)\n",
    "    R.fwd_pass();\n",
    "    \n",
    "    err = R.bwd_pass();\n",
    "    err_curve.append(err);\n",
    "    \n",
    "    if(n%500 == 0):\n",
    "        \n",
    "        print(n,\"err:\",err,\" R.learningRate:\", R.learningRate,\"dropout_threshold:\",R.dropout_threshold)\n",
    "        seed = encode(n % vocab_size,vocab_size)\n",
    "        print(ix_to_char[n % vocab_size])\n",
    "        result = [];\n",
    "        R.h  = np.zeros(sizeHidden)\n",
    "        R.c  = np.zeros(sizeHidden)\n",
    "        print(\"<Inference>:\")\n",
    "        for i in range(40):\n",
    "            ret = R.inference(seed)\n",
    "            result.append(ret)\n",
    "            seed = encode(ret,vocab_size)\n",
    "        decode = ''.join([ix_to_char[ch] for ch in result] )\n",
    "        print(decode)\n",
    "        \n",
    "        print(\"\\n<Predict>:\")\n",
    "        inputs  = [char_to_ix[ch] for ch in data[position:position+seq_length]]\n",
    "        targets = [char_to_ix[ch] for ch in data[position+1:position+seq_length+1]] \n",
    "        result = [];\n",
    "        compare = [];\n",
    "        for i in range(40):\n",
    "            ret = R.inference(encode(inputs[i],vocab_size))\n",
    "            result.append(ret)\n",
    "            compare.append(targets[i])\n",
    "        in_decode = ''.join([ix_to_char[ch] for ch in result] )\n",
    "        cm_decode = ''.join([ix_to_char[ch] for ch in compare] )\n",
    "        print(\"<Predict>:\",in_decode)\n",
    "        print(\"<Targets>:\",cm_decode)\n",
    "    position += seq_length;\n",
    "    n += 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4]\n"
     ]
    }
   ],
   "source": [
    "k = [1,2,3,4]\n",
    "u = k[3:]\n",
    "print(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYnVLAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x22a1db53780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(-np.array(err_curve));\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
