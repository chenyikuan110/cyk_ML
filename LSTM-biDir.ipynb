{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "# Helper functions\n",
    "def softmax(array):\n",
    "    return np.exp(array)/ np.sum(np.exp(array)) # return an array\n",
    "\n",
    "def sigmoid(x):\n",
    "    return (1/(1+np.exp(-x)))\n",
    "\n",
    "def sigmoid_deriv(y):\n",
    "    return (y*(1-y))\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def tanh_deriv(y):\n",
    "    return 1 - pow(np.tanh(y),2)\n",
    "\n",
    "# RNN\n",
    "class lstmRNN:\n",
    "    \n",
    "    def __init__ (self, lenIn, lenOut, lenRec, sizeHidden, inputs_encoded, targets, learningRate):\n",
    "        \n",
    "        # Hyper parameters\n",
    "        self.lenIn          = lenIn\n",
    "        self.lenOut         = lenOut\n",
    "        self.lenRec         = lenRec\n",
    "        self.sizeHidden     = sizeHidden\n",
    "        self.learningRate   = learningRate\n",
    "        \n",
    "        # input & expected output\n",
    "        self.inputs_encoded = inputs_encoded;\n",
    "        self.targets = targets;\n",
    "        \n",
    "        # parameters for inference\n",
    "        self.x  = np.zeros(lenIn)  \n",
    "        self.y  = np.zeros(lenOut)\n",
    "        self.hls_infer = np.zeros((lenRec,sizeHidden))\n",
    "        self.hrs_infer = np.zeros((lenRec,sizeHidden))\n",
    "        self.cls_infer = np.zeros((lenRec,sizeHidden))\n",
    "        self.crs_infer = np.zeros((lenRec,sizeHidden))\n",
    "        self.W  = np.zeros((lenOut,sizeHidden*2)) # for the last fully connected layer\n",
    "        self.b  = np.zeros(lenOut)\n",
    "       \n",
    "        # for training phase \n",
    "        self.xs = np.zeros((lenRec,lenIn))\n",
    "        self.ys = np.zeros((lenRec,lenOut))\n",
    "        self.hls = np.zeros((lenRec,sizeHidden))\n",
    "        self.hrs = np.zeros((lenRec,sizeHidden))\n",
    "        self.cls = np.zeros((lenRec,sizeHidden))\n",
    "        self.crs = np.zeros((lenRec,sizeHidden))\n",
    "        self.GW = np.zeros((lenOut,sizeHidden*2)) # Gradient, for W-update using RMSprop\n",
    "        self.Gb = np.zeros(lenOut)\n",
    "        \n",
    "        # for training phase bookkeeping\n",
    "        self.flg = np.zeros((lenRec,sizeHidden)) # forget gate\n",
    "        self.frg = np.zeros((lenRec,sizeHidden))\n",
    "        self.ilg = np.zeros((lenRec,sizeHidden)) # input  gate\n",
    "        self.irg = np.zeros((lenRec,sizeHidden))\n",
    "        self.olg = np.zeros((lenRec,sizeHidden)) # output gate\n",
    "        self.org = np.zeros((lenRec,sizeHidden))\n",
    "        self.mlc = np.zeros((lenRec,sizeHidden)) # memory cell\n",
    "        self.mrc = np.zeros((lenRec,sizeHidden))\n",
    "        \n",
    "        # LSTM class\n",
    "        self.LSTM_L = LSTM(sizeHidden+lenIn,sizeHidden,lenRec,learningRate)\n",
    "        self.LSTM_R = LSTM(sizeHidden+lenIn,sizeHidden,lenRec,learningRate)\n",
    "        \n",
    "        ''' end of lstmRNN.__init__ '''\n",
    "       \n",
    "    ''' This is used when mini-batch is used '''            \n",
    "    def update_inputs_targets(self, inputs_encoded, targets):\n",
    "        self.inputs_encoded  = inputs_encoded\n",
    "        self.targets         = targets\n",
    "    \n",
    "    def fwd_pass(self): \n",
    "        # fwd layer\n",
    "        prev_h = np.zeros_like(self.hls[0])\n",
    "        for t in range(0,self.lenRec):\n",
    "            # update input - edited until here\n",
    "            self.x    = self.inputs_encoded[t]\n",
    "            self.xs[t]= self.inputs_encoded[t]\n",
    "            \n",
    "            self.LSTM_L.hx = np.hstack((prev_h, self.x));\n",
    "           \n",
    "            c,h,f,i,m,o = self.LSTM_L.fwd_pass()\n",
    "            # bookkeeping\n",
    "            self.cls[t] = c\n",
    "            self.hls[t] = h\n",
    "            self.flg[t] = f\n",
    "            self.ilg[t] = i\n",
    "            self.mlc[t] = m\n",
    "            self.olg[t] = o\n",
    "            prev_h = self.hls[t]\n",
    "                           \n",
    "        # bwd layer\n",
    "        prev_h = np.zeros_like(self.hrs[0])                 \n",
    "        for t in reversed(range(0,self.lenRec)):\n",
    "            # update input\n",
    "            self.x    = self.xs[t]\n",
    "            self.LSTM_R.hrx = np.hstack((prev_h, self.x));\n",
    "           \n",
    "            c,h,f,i,m,o = self.LSTM_R.fwd_pass()\n",
    "            # bookkeeping\n",
    "            self.crs[t] = c\n",
    "            self.hrs[t] = h\n",
    "            self.frg[t] = f\n",
    "            self.irg[t] = i\n",
    "            self.mrc[t] = m\n",
    "            self.org[t] = o\n",
    "            prev_h = self.hrs[t] \n",
    "                           \n",
    "            # output layer - fully connected layer\n",
    "            self.ys[t] = np.dot(self.W,np.hstack((self.hls[t],self.hrs[t]))) + self.b            \n",
    "        return;              \n",
    "    \n",
    "    def bwd_pass(self):        \n",
    "\n",
    "        avg_loss = 0; # using cross entropy average\n",
    "        h2next_grad  = np.zeros(self.sizeHidden)\n",
    "        c2next_grad  = np.zeros(self.sizeHidden)\n",
    "        \n",
    "        # output bp\n",
    "        W_grad   = np.zeros((self.lenOut,self.sizeHidden*2))\n",
    "        b_grad  = np.zeros(self.lenOut)\n",
    "                                \n",
    "        hlxf_grad  = np.zeros((self.sizeHidden,self.LSTM_L.lenIn));\n",
    "        hrxf_grad  = np.zeros((self.sizeHidden,self.LSTM_R.lenIn));   \n",
    "        hlxi_grad  = np.zeros((self.sizeHidden,self.LSTM_L.lenIn));\n",
    "        hrxi_grad  = np.zeros((self.sizeHidden,self.LSTM_R.lenIn));\n",
    "        hlxm_grad  = np.zeros((self.sizeHidden,self.LSTM_L.lenIn));\n",
    "        hrxm_grad  = np.zeros((self.sizeHidden,self.LSTM_R.lenIn));\n",
    "        hlxo_grad  = np.zeros((self.sizeHidden,self.LSTM_L.lenIn));\n",
    "        hrxo_grad  = np.zeros((self.sizeHidden,self.LSTM_R.lenIn));\n",
    "\n",
    "        flb_grad   = np.zeros((self.sizeHidden));\n",
    "        frb_grad   = np.zeros((self.sizeHidden)); \n",
    "        ilb_grad   = np.zeros((self.sizeHidden));\n",
    "        irb_grad   = np.zeros((self.sizeHidden)); \n",
    "        mlb_grad   = np.zeros((self.sizeHidden));\n",
    "        mrb_grad   = np.zeros((self.sizeHidden)); \n",
    "        olb_grad   = np.zeros((self.sizeHidden));\n",
    "        orb_grad   = np.zeros((self.sizeHidden)); \n",
    "                                \n",
    "        # propagates through time and layers      \n",
    "        dh = np.zeros((self.lenRec,self.sizeHidden*2))                \n",
    "\n",
    "        for t in reversed(range(0,self.lenRec)):\n",
    "            \n",
    "            prob = softmax(self.ys[t]) # prevent zero\n",
    "            prob_fix  = prob + 1e-9\n",
    "\n",
    "            # cross entropy\n",
    "            err       = np.log(prob_fix[int(self.targets[t])])\n",
    "            avg_loss += err\n",
    "     \n",
    "            dy = copy.deepcopy(prob)\n",
    "            dy[int(self.targets[t])] -= 1\n",
    "            \n",
    "            W_grad += np.dot((np.atleast_2d(dy)).T,np.atleast_2d(np.hstack((self.hls[t],self.hrs[t])) ))\n",
    "            b_grad += dy\n",
    "            \n",
    "            dh[t] = np.dot(self.W.T,dy) \n",
    "                                \n",
    "        for t in reversed(range(0,self.lenRec)):                 \n",
    "            dhl = dh[t,:self.sizeHidden] + h2next_grad         \n",
    "            x_grad  = np.zeros(self.lenIn)\n",
    "            \n",
    "            if(t > 0):\n",
    "                prev_h,prev_c = self.hls[t-1],self.cls[t-1]\n",
    "            else:\n",
    "                prev_h,prev_c = np.zeros_like(self.hls[0]),np.zeros_like(self.cls[0])\n",
    "                \n",
    "            self.LSTM_L.hx = np.hstack((prev_h,self.xs[t]))\n",
    "            self.LSTM_L.c  = self.cls[t]\n",
    "\n",
    "            dhlxf, dhlxi, dhlxm, dhlxo, dblf, dbli, dblm, dblo,c2next_grad, h2next_grad,x_grad = \\\n",
    "            self.LSTM_L.bwd_pass( dhl, prev_c, self.flg[t],self.ilg[t],self.mlc[t],self.olg[t], c2next_grad);\n",
    "            \n",
    "            hlxf_grad  +=  dhlxf\n",
    "            hlxi_grad  +=  dhlxi\n",
    "            hlxm_grad  +=  dhlxm\n",
    "            hlxo_grad  +=  dhlxo         \n",
    "            flb_grad   +=  dblf\n",
    "            ilb_grad   +=  dbli\n",
    "            mlb_grad   +=  dblm\n",
    "            olb_grad   +=  dblo\n",
    "                                \n",
    "        h2next_grad  = np.zeros(self.sizeHidden)     \n",
    "        c2next_grad  = np.zeros(self.sizeHidden)\n",
    "        for t in range(0,self.lenRec):                 \n",
    "            dhr = dh[t,self.sizeHidden:] + h2next_grad         \n",
    "            x_grad  = np.zeros(self.lenIn)\n",
    "            \n",
    "            if(t < self.lenRec-1):\n",
    "                prev_h,prev_c = self.hrs[t+1],self.crs[t+1]\n",
    "            else:\n",
    "                prev_h,prev_c = np.zeros_like(self.hrs[0]),np.zeros_like(self.crs[0])\n",
    "                \n",
    "            self.LSTM_R.hx = np.hstack((prev_h,self.xs[t]))\n",
    "            self.LSTM_R.c  = self.crs[t]\n",
    "\n",
    "            dhrxf, dhrxi, dhrxm, dhrxo, dbrf, dbri, dbrm, dbro,c2next_grad, h2next_grad,x_grad = \\\n",
    "            self.LSTM_R.bwd_pass( dhr, prev_c, self.frg[t],self.irg[t],self.mrc[t],self.org[t], c2next_grad);\n",
    "            \n",
    "            hrxf_grad  +=  dhrxf\n",
    "            hrxi_grad  +=  dhrxi\n",
    "            hrxm_grad  +=  dhrxm\n",
    "            hrxo_grad  +=  dhrxo         \n",
    "            frb_grad   +=  dbrf\n",
    "            irb_grad   +=  dbri\n",
    "            mrb_grad   +=  dbrm\n",
    "            orb_grad   +=  dbro\n",
    "                                \n",
    "        self.LSTM_L.update(hlxf_grad/self.lenRec, hlxi_grad/self.lenRec,\\\n",
    "                           hlxm_grad/self.lenRec, hlxo_grad/self.lenRec, \\\n",
    "                           flb_grad /self.lenRec, ilb_grad /self.lenRec, \\\n",
    "                           mlb_grad /self.lenRec, olb_grad /self.lenRec)\n",
    "        self.LSTM_R.update(hrxf_grad/self.lenRec, hrxi_grad/self.lenRec,\\\n",
    "                           hrxm_grad/self.lenRec, hrxo_grad/self.lenRec, \\\n",
    "                           frb_grad /self.lenRec, irb_grad /self.lenRec, \\\n",
    "                           mrb_grad /self.lenRec, orb_grad /self.lenRec)                                          \n",
    "                         \n",
    "                                                  \n",
    "        self.update(W_grad/self.lenRec,b_grad/self.lenRec);\n",
    "        return avg_loss/self.lenRec;\n",
    "            \n",
    "    def update(self, W_grad, b_grad):\n",
    "        self.GW = self.GW + W_grad**2;\n",
    "        self.W -= self.learningRate/np.sqrt(self.GW + 1e-8) * W_grad;\n",
    "        self.Gb = self.Gb + b_grad**2;\n",
    "        self.b -= self.learningRate/np.sqrt(self.Gb + 1e-8) * b_grad;\n",
    "\n",
    "    def inference(self,xs):\n",
    "        # fwd layer\n",
    "        prev_h = np.zeros_like(self.hls_infer[0])\n",
    "        for t in range(0,self.lenRec):\n",
    "            # update input\n",
    "            self.x    = xs[t]\n",
    "            \n",
    "            self.LSTM_L.hx = np.hstack((prev_h, self.x));\n",
    "           \n",
    "            c,h,f,i,m,o = self.LSTM_L.fwd_pass()\n",
    "            # bookkeeping\n",
    "            self.hls_infer[t] = h\n",
    "            self.cls_infer[t] = c\n",
    "            prev_h = self.hls_infer[t]\n",
    "           \n",
    "        # bwd layer\n",
    "        prev_h = np.zeros_like(self.hrs[0])                 \n",
    "        for t in reversed(range(0,self.lenRec)):\n",
    "            # update input\n",
    "            self.x    = xs[t]\n",
    "            \n",
    "            self.LSTM_R.hx = np.hstack((prev_h, self.x));\n",
    "           \n",
    "            c,h,f,i,m,o = self.LSTM_R.fwd_pass()\n",
    "            # bookkeeping\n",
    "            self.hrs_infer[t] = h\n",
    "            self.crs_infer[t] = c\n",
    "            prev_h = self.hrs_infer[t]\n",
    "                           \n",
    "            # output layer - fully connected layer\n",
    "        y = np.dot(self.W,np.hstack((self.hls_infer[self.lenRec-1],self.hrs_infer[self.lenRec-1]))) + self.b \n",
    "        p = softmax(y)\n",
    "             \n",
    "        return np.random.choice(range(self.lenOut), p=p.ravel())\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LSTM:\n",
    "    \n",
    "    def __init__ (self,lenIn,sizeHidden,lenRec,learningRate):\n",
    "        self.lenIn        = lenIn\n",
    "        self.sizeHidden   = sizeHidden\n",
    "        self.lenRec       = lenRec\n",
    "        self.learningRate = learningRate\n",
    "        \n",
    "        # hx == x is x and h horizontally stacked together\n",
    "        self.hx = np.zeros(lenIn)\n",
    "        self.c = np.zeros(sizeHidden)\n",
    "        self.h = np.zeros(sizeHidden)\n",
    "        \n",
    "        # Weight matrices\n",
    "        self.fW = np.random.random((sizeHidden,lenIn));\n",
    "        self.iW = np.random.random((sizeHidden,lenIn));\n",
    "        self.mW = np.random.random((sizeHidden,lenIn)); # cell state\n",
    "        self.oW = np.random.random((sizeHidden,lenIn));\n",
    "                             \n",
    "        # biases\n",
    "        self.fb = np.zeros(sizeHidden);\n",
    "        self.ib = np.zeros(sizeHidden); \n",
    "        self.mb = np.zeros(sizeHidden); \n",
    "        self.ob = np.zeros(sizeHidden); \n",
    "               \n",
    "        # for RMSprop only\n",
    "        self.GfW = np.random.random((sizeHidden,lenIn));\n",
    "        self.GiW = np.random.random((sizeHidden,lenIn));\n",
    "        self.GmW = np.random.random((sizeHidden,lenIn)); \n",
    "        self.GoW = np.random.random((sizeHidden,lenIn));\n",
    "                             \n",
    "        self.Gfb = np.zeros(sizeHidden);\n",
    "        self.Gib = np.zeros(sizeHidden); \n",
    "        self.Gmb = np.zeros(sizeHidden);\n",
    "        self.Gob = np.zeros(sizeHidden); \n",
    "        \n",
    "        ''' end of LSTM.__init__ '''\n",
    "        \n",
    "    def fwd_pass(self):\n",
    "        f       = sigmoid(np.dot(self.fW, self.hx) + self.fb)\n",
    "        i       = sigmoid(np.dot(self.iW, self.hx) + self.ib)\n",
    "        m       = tanh(   np.dot(self.mW, self.hx) + self.mb)        \n",
    "        o       = sigmoid(np.dot(self.oW, self.hx) + self.ob)\n",
    "        self.c *= f\n",
    "        self.c += i * m\n",
    "        self.h  = o * tanh(self.c)\n",
    "        \n",
    "        return self.c, self.h, f, i, m, o;\n",
    "    \n",
    "    def bwd_pass(self, dh, prev_c, f, i, m, o, c_g):\n",
    "        \n",
    "        dh = np.clip(dh, -6, 6);       \n",
    "        # h = o*tanh(c)\n",
    "        do  = tanh(self.c) * dh\n",
    "        do  = sigmoid_deriv(o)*do\n",
    "        dhxo = np.dot((np.atleast_2d(do)).T,np.atleast_2d(self.hx)) \n",
    "        \n",
    "        # h = o*tanh(c) - add c_g (c_grad in next timestep, account for the branch here)\n",
    "        dcs = dh * o * tanh_deriv(self.c) + c_g\n",
    "        dcs = np.clip(dcs, -6, 6); \n",
    "        \n",
    "        # c = c_prev * f + m * i\n",
    "        dm = i * dcs\n",
    "        dm = tanh_deriv(m) * dm\n",
    "        dhxm = np.dot((np.atleast_2d(dm)).T,np.atleast_2d(self.hx)) \n",
    "        \n",
    "        # c = c_prev * f + m * i\n",
    "        di  = m * dcs\n",
    "        di  = sigmoid_deriv(i) * di\n",
    "        dhxi = np.dot((np.atleast_2d(di)).T,np.atleast_2d(self.hx)) \n",
    "        \n",
    "        # c = c_prev * f + m * i\n",
    "        df = prev_c * dcs\n",
    "        df = sigmoid_deriv(f) * df\n",
    "        dhxf = np.dot((np.atleast_2d(df)).T,np.atleast_2d(self.hx)) \n",
    "        \n",
    "        # c = c_prev * f + m * i\n",
    "        c_grad  = dcs * f\n",
    "        hx_grad = np.dot(self.fW.T, df) + np.dot(self.iW.T, di) +\\\n",
    "                          np.dot(self.oW.T, do) + np.dot(self.mW.T, dm)\n",
    "        \n",
    "        \n",
    "        return dhxf,dhxi,dhxm,dhxo,df,di,dm,do,c_grad,hx_grad[:self.sizeHidden],hx_grad[self.sizeHidden:];\n",
    "    \n",
    "    def update(self, f_grad, i_grad, m_grad, o_grad, fb_grad, ib_grad, mb_grad, ob_grad):\n",
    "\n",
    "        self.GfW = 0.9*self.GfW + 0.1*f_grad**2\n",
    "        self.GiW = 0.9*self.GiW + 0.1*i_grad**2\n",
    "        self.GmW = 0.9*self.GmW + 0.1*m_grad**2\n",
    "        self.GoW = 0.9*self.GoW + 0.1*o_grad**2\n",
    "        \n",
    "        self.Gfb = 0.9*self.Gfb + 0.1*fb_grad**2\n",
    "        self.Gib = 0.9*self.Gib + 0.1*ib_grad**2\n",
    "        self.Gmb = 0.9*self.Gmb + 0.1*mb_grad**2\n",
    "        self.Gob = 0.9*self.Gob + 0.1*ob_grad**2\n",
    "        \n",
    "        self.fW -= self.learningRate/np.sqrt(self.GfW + 1e-8) * f_grad\n",
    "        self.iW -= self.learningRate/np.sqrt(self.GiW + 1e-8) * i_grad\n",
    "        self.mW -= self.learningRate/np.sqrt(self.GmW + 1e-8) * m_grad\n",
    "        self.oW -= self.learningRate/np.sqrt(self.GoW + 1e-8) * o_grad\n",
    "        self.fb -= self.learningRate/np.sqrt(self.Gfb + 1e-8) * fb_grad\n",
    "        self.ib -= self.learningRate/np.sqrt(self.Gib + 1e-8) * ib_grad\n",
    "        self.mb -= self.learningRate/np.sqrt(self.Gmb + 1e-8) * mb_grad\n",
    "        self.ob -= self.learningRate/np.sqrt(self.Gob + 1e-8) * ob_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "431677 ,  79\n",
      "{'T': 0, 'L': 1, 'r': 2, '-': 3, 'm': 4, '\\\\': 5, 'u': 6, 'R': 7, '.': 8, ';': 9, \"'\": 10, 'E': 11, 'J': 12, 'a': 13, ' ': 14, 'k': 15, 'K': 16, '6': 17, '0': 18, ')': 19, 'q': 20, 't': 21, '8': 22, 'w': 23, 'V': 24, '\"': 25, '7': 26, '\\t': 27, 'p': 28, 'x': 29, '5': 30, 'G': 31, 'B': 32, ':': 33, '?': 34, 'W': 35, 'Z': 36, 'v': 37, 'P': 38, 'S': 39, 'H': 40, 'A': 41, 'O': 42, '\\n': 43, 'i': 44, 'Q': 45, '*': 46, 'N': 47, '!': 48, 'X': 49, 'o': 50, 's': 51, 'j': 52, 'M': 53, 'F': 54, 'd': 55, '(': 56, '4': 57, 'D': 58, 'y': 59, 'C': 60, 'b': 61, 'g': 62, 'z': 63, 'c': 64, '9': 65, 'h': 66, '2': 67, 'e': 68, 'Y': 69, 'I': 70, 'n': 71, 'l': 72, 'f': 73, 'U': 74, '3': 75, '~': 76, ',': 77, '1': 78}\n",
      "{0: 'T', 1: 'L', 2: 'r', 3: '-', 4: 'm', 5: '\\\\', 6: 'u', 7: 'R', 8: '.', 9: ';', 10: \"'\", 11: 'E', 12: 'J', 13: 'a', 14: ' ', 15: 'k', 16: 'K', 17: '6', 18: '0', 19: ')', 20: 'q', 21: 't', 22: '8', 23: 'w', 24: 'V', 25: '\"', 26: '7', 27: '\\t', 28: 'p', 29: 'x', 30: '5', 31: 'G', 32: 'B', 33: ':', 34: '?', 35: 'W', 36: 'Z', 37: 'v', 38: 'P', 39: 'S', 40: 'H', 41: 'A', 42: 'O', 43: '\\n', 44: 'i', 45: 'Q', 46: '*', 47: 'N', 48: '!', 49: 'X', 50: 'o', 51: 's', 52: 'j', 53: 'M', 54: 'F', 55: 'd', 56: '(', 57: '4', 58: 'D', 59: 'y', 60: 'C', 61: 'b', 62: 'g', 63: 'z', 64: 'c', 65: '9', 66: 'h', 67: '2', 68: 'e', 69: 'Y', 70: 'I', 71: 'n', 72: 'l', 73: 'f', 74: 'U', 75: '3', 76: '~', 77: ',', 78: '1'}\n",
      "Harry Potter and the Sorcerer's Stone\n",
      "CHAPTER ONE\n",
      "THE BOY WHO LIVED\n",
      "Mr. and\n",
      "inputs [40, 13, 2, 2, 59, 14, 38, 50, 21, 21, 68, 2, 14, 13, 71, 55, 14, 21, 66, 68, 14, 39, 50, 2, 64, 68, 2, 68, 2, 10, 51, 14, 39, 21, 50, 71, 68, 43, 60, 40, 41, 38, 0, 11, 7, 14, 42, 47, 11, 43, 0, 40, 11, 14, 32, 42, 69, 14, 35, 40, 42, 14, 1, 70, 24, 11, 58, 43, 53, 2, 8, 14, 13, 71, 55]\n",
      "arry Potter and the Sorcerer's Stone\n",
      "CHAPTER ONE\n",
      "THE BOY WHO LIVED\n",
      "Mr. and \n",
      "targets [13, 2, 2, 59, 14, 38, 50, 21, 21, 68, 2, 14, 13, 71, 55, 14, 21, 66, 68, 14, 39, 50, 2, 64, 68, 2, 68, 2, 10, 51, 14, 39, 21, 50, 71, 68, 43, 60, 40, 41, 38, 0, 11, 7, 14, 42, 47, 11, 43, 0, 40, 11, 14, 32, 42, 69, 14, 35, 40, 42, 14, 1, 70, 24, 11, 58, 43, 53, 2, 8, 14, 13, 71, 55, 14]\n",
      "!!!! 431677\n",
      "0 err: -4.36944777346702\n",
      "RYWOdTT.h.OAINHnA'oPEY.ysLtHLMsoPnnC\n",
      "RNENyWo\n",
      "hDMdD\n",
      "\n",
      "500 err: -3.2503359904054583\n",
      "lnniDa bnhwegreti ghosualh c gneil !oolaaDmthetado\n",
      "\n",
      "1000 err: -3.0219654032588052\n",
      " ava ct hu id -thuewhIe gtaonhhcafw,otadso atApa, \n",
      "\n",
      "1500 err: -3.154879634899492\n",
      "  o\"lnhuinh ta ng  o'Ci-stC\"e\n",
      "uobeenl ecrOer'H wel\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-19b02ccacb10>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[0mR\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfwd_pass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     \u001b[0merr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mR\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbwd_pass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m500\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-25-2e236eddc4b3>\u001b[0m in \u001b[0;36mbwd_pass\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    201\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLSTM_R\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcrs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 203\u001b[1;33m             \u001b[0mdhrxf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdhrxi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdhrxm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdhrxo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdbrf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdbri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdbrm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdbro\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mc2next_grad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh2next_grad\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_grad\u001b[0m \u001b[1;33m=\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLSTM_R\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbwd_pass\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mdhr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprev_c\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mirg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmrc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc2next_grad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m             \u001b[0mhrxf_grad\u001b[0m  \u001b[1;33m+=\u001b[0m  \u001b[0mdhrxf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-26-47281a8e9469>\u001b[0m in \u001b[0;36mbwd_pass\u001b[1;34m(self, dh, prev_c, f, i, m, o, c_g)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mdm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mdcs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[0mdm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtanh_deriv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mdm\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m         \u001b[0mdhxm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[1;31m# c = c_prev * f + m * i\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data = open('HP1.txt','r', encoding=\"utf8\").read();\n",
    "chars = list(set(data))\n",
    "data_size, vocab_size = len(data), len(chars)\n",
    "print(data_size,\", \",vocab_size)\n",
    "\n",
    "char_to_ix = {ch:i for i, ch in enumerate(chars)}\n",
    "ix_to_char = {i:ch for i,ch in enumerate(chars)}\n",
    "print(char_to_ix)\n",
    "print(ix_to_char)\n",
    "\n",
    "def encode(idx,num_entry):\n",
    "    ret = np.zeros(num_entry)\n",
    "    ret[idx] = 1\n",
    "    return ret;\n",
    "\n",
    "def encode_array(array,num_entry):\n",
    "    xs = np.zeros((len(array),num_entry))\n",
    "    for i in range(len(array)):\n",
    "        xs[i][array[i]] = 1; \n",
    "    return xs;\n",
    "\n",
    "\n",
    "seq_length,position = 75,0\n",
    "inputs = [char_to_ix[ch] for ch in data[position:position+seq_length]]\n",
    "print(data[position:position+seq_length])\n",
    "print(\"inputs\",inputs)\n",
    "\n",
    "targets = [char_to_ix[ch] for ch in data[position+1:position+seq_length+1]] \n",
    "print(data[position+1:position+seq_length+1])\n",
    "print(\"targets\",targets)\n",
    "\n",
    "n,position = 0,0;\n",
    "epoch = 30*1000;\n",
    "lenIn, lenOut, lenRec = vocab_size,vocab_size, seq_length\n",
    "sizeHidden, numHiddenLayer = 80,1;\n",
    "learningRate = 0.1;\n",
    "\n",
    "\n",
    "R = lstmRNN(lenIn, lenOut, lenRec, sizeHidden, encode_array(inputs,vocab_size),targets, learningRate)\n",
    "\n",
    "# training\n",
    "while n<epoch:\n",
    "    \n",
    "    if(position+seq_length+1 >= len(data) or n == 0):\n",
    "        print(\"!!!!\",len(data))\n",
    "        position = 0;\n",
    "        \n",
    "    inputs  = [char_to_ix[ch] for ch in data[position:position+seq_length]]\n",
    "    targets = [char_to_ix[ch] for ch in data[position+1:position+seq_length+1]] \n",
    "\n",
    "    R.update_inputs_targets(encode_array(inputs,vocab_size),targets)\n",
    "    R.fwd_pass();\n",
    "    \n",
    "    err = R.bwd_pass();\n",
    "    \n",
    "    if(n%500 == 0):\n",
    "        print(n,\"err:\",err)\n",
    "        infer_in  = [char_to_ix[ch] for ch in data[position:position+seq_length]]\n",
    "        infer_in_enc = encode_array(infer_in,vocab_size)\n",
    "        result = [];\n",
    "\n",
    "        for i in range(50):\n",
    "            ret = R.inference(infer_in_enc)\n",
    "            #print(i,\":\",ret)\n",
    "            result.append(ret)\n",
    "            infer_in.append(ret)\n",
    "            infer_in_enc = encode_array(infer_in[i+1:],vocab_size)\n",
    "        decode = ''.join([ix_to_char[ch] for ch in result] )\n",
    "        print(decode+'\\n')\n",
    "\n",
    "    position += seq_length;\n",
    "    n += 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
